{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrkZWMLZB8z"
      },
      "source": [
        "# Tarea 1: Introducci√≥n, Vector Space Models, Information Retrieval y Language Models</h1>\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto√±o 2024)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97b4IJjZGxM"
      },
      "source": [
        "## Tarjeta de identificaci√≥n\n",
        "\n",
        "**Nombres:**\n",
        "\n",
        "```- Ignacio Albornoz```\n",
        "\n",
        "```- Eduardo Silva```\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** 10/04.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:** 4 horas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKcZMFlmZ3b9"
      },
      "source": [
        "## Instrucciones\n",
        "Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te√≥ricos de las primeras semanas de clases, enfocado principalmente en **Information Retrieval (IR)**, **Vector Space Models** y **Language Models**. Si a√∫n no has visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una parte te√≥rica que busca evaluar conceptos vistos en clases. Seguido por una parte pr√°ctica con el f√≠n de introducirlos a la programaci√≥n en Python enfocada en NLP.\n",
        "\n",
        "* La tarea es en **grupo** (maximo hasta 3 personas).\n",
        "* La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "* El formato de entrega es este mismo Jupyter Notebook.\n",
        "* Al momento de la revisi√≥n su c√≥digo ser√° ejecutado. Por favor verifiquen que su entrega no tenga errores de compilaci√≥n.\n",
        "* Completar la tarjeta de identificaci√≥n. Sin ella no podr√° tener nota."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnTrhOKraAw2"
      },
      "source": [
        "## Material de referencia\n",
        "\n",
        "Diapositivas del curso üìÑ\n",
        "    \n",
        "- [Introducci√≥n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
        "- [Probabilistic Language Models](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-PLM.pdf)\n",
        "\n",
        "Videos del curso üì∫\n",
        "- Introducci√≥n  [Parte 1](https://www.youtube.com/watch?v=HEKTNOttGvU)  [Parte 2](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "\n",
        "- Information Retrieval [Parte 1](https://www.youtube.com/watch?v=FXIVClF370w&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) [Parte 2](https://www.youtube.com/watch?v=f8nG1EMmPZk&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3)\n",
        "- Probabilistic Language Models [Parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) [Parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5) [Parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6) [Parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install nltk\n",
        "#!pip install pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7w4BT1qmChV"
      },
      "source": [
        "## P1. Tokenizaci√≥n\n",
        "\n",
        "En el primer ejercicio veremos la dificultad de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlgSZrB2oe1H",
        "outputId": "c7ae0581-5774-4700-c975-55d344d49ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directorio de trabajo actual: /home/ignacio/2024-1/NLP/nlp_t1\n",
            "No est√° en Google Colab. Se dejara el path de archivo local.\n"
          ]
        }
      ],
      "source": [
        "# En caso de desarrollar la tarea desde colab, con el siguiente c√≥digo podemos cargar los archivos desde drive:\n",
        "\n",
        "import os\n",
        "\n",
        "# Imprime el directorio de trabajo actual\n",
        "print(\"Directorio de trabajo actual:\", os.getcwd())\n",
        "\n",
        "try:\n",
        "    # Intenta importar el m√≥dulo espec√≠fico de Colab y montar Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    # Especifica la ruta de acceso en Google Drive\n",
        "    path = '/content/drive/MyDrive/nlp/oh_algoritmo.txt'\n",
        "except ImportError:\n",
        "    # Maneja el caso cuando se ejecute fuera de Colab, e.g., en Jupyter\n",
        "    print('No est√° en Google Colab. Se dejara el path de archivo local.')\n",
        "    # Especifica la ruta de acceso local\n",
        "    path = './oh_algoritmo.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCKFrnZcoy2F"
      },
      "source": [
        "Ejecute el c√≥digo a continuaci√≥n para cargar el ejemplo. Recuerde realizar la modificaci√≥n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9CteGwEmDKw",
        "outputId": "eec53292-dd24-482a-ba9d-4ebb3f4585fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canci√≥n\n",
            "¬øQu√© algoritmo la pari√≥?\n",
            "Me pregunto si fui yo\n",
            "¬øLa elegiste o te eligi√≥?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con √âl\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedr√≠o es un cauce vac√≠o\n",
            "Un barco que no tiene r√≠o\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, t√∫ tambi√©n\n",
            "Pero no queda claro qui√©n\n",
            "Tiene del mango a la sart√©n\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(path, \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurri√≥ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPSSO2kJoArL"
      },
      "source": [
        "Fuente: https://genius.com/Jorge-drexler-oh-algoritmo-lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fG0hLbHg9dn"
      },
      "source": [
        "### Pregunta 1.a (0.25 puntos)\n",
        "\n",
        "Dise√±e una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Es libre de elegir la forma de tokenizar mientras no utilice librer√≠as con tokenizadores ya implementados. Puede utilizar la librer√≠a **re** importada para trabajar s√≠mbolos. Explique su razonamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5P7rk4VRm6Az"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qiRMkdjwazFT"
      },
      "outputs": [],
      "source": [
        "def get_tokens(texto):\n",
        "\n",
        "\n",
        "    pattern = r'\\w+'\n",
        "\n",
        "    matches = re.findall(pattern, texto)\n",
        "    return matches\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDBZn4kOm7uH",
        "outputId": "3dd9224f-68d1-4fc1-a2da-d5bba73a2af3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Letra',\n",
              " 'de',\n",
              " 'Oh',\n",
              " 'Algoritmo',\n",
              " 'ft',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'Refr√°n',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Estribillo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Verso',\n",
              " '1',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'Wait',\n",
              " 'what',\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " 'What',\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " 'Mmm',\n",
              " 'I',\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " 's',\n",
              " 'big',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " 'I',\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Pre',\n",
              " 'Estribillo',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " 'Estribillo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Verso',\n",
              " '2',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " 'esta',\n",
              " 'canci√≥n',\n",
              " 'Qu√©',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'pari√≥',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligi√≥',\n",
              " 'Verso',\n",
              " '3',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " '√âl',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedr√≠o',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vac√≠o',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'r√≠o',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " 'Verso',\n",
              " '4',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " 't√∫',\n",
              " 'tambi√©n',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'qui√©n',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sart√©n',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " 'Ven',\n",
              " 'ven',\n",
              " 'ven',\n",
              " 'Refr√°n',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Wow']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = get_tokens(texto)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpZKljrotLa"
      },
      "source": [
        "### Pregunta 1.b (0.25 puntos)\n",
        "Explique su implementaci√≥n aqu√≠:\n",
        "> La implementaci√≥n de forma manual consiste en utilizar la libreria \"re\" para buscar un patr√≥n en particular de un string. El patron a buscar es cualquier palabra que encuentre en el String, el cual guarda en una lista posteriomente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwAKWZvofEp"
      },
      "source": [
        "Implementaci√≥n con la libreria NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GR2Z0lnnPB9",
        "outputId": "088f2104-ffd3-473d-ab3c-d376f8fe46c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Letra',\n",
              " 'de',\n",
              " '\"¬°',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'Algoritmo',\n",
              " '!\"',\n",
              " 'ft',\n",
              " '.',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " '[',\n",
              " 'Refr√°n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '1',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'Wait',\n",
              " ',',\n",
              " 'what',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " '?',\n",
              " 'What',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " '?',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " \"'\",\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " '?',\n",
              " 'Mmm',\n",
              " ',',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " \"'\",\n",
              " 's',\n",
              " 'big',\n",
              " '-',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " ':',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " '[',\n",
              " 'Pre',\n",
              " '-',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '2',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " ',',\n",
              " 'esta',\n",
              " 'canci√≥n',\n",
              " '¬ø',\n",
              " 'Qu√©',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'pari√≥',\n",
              " '?',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " '¬ø',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligi√≥',\n",
              " '?',\n",
              " '[',\n",
              " 'Verso',\n",
              " '3',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " '√âl',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedr√≠o',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vac√≠o',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'r√≠o',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " '[',\n",
              " 'Verso',\n",
              " '4',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " ',',\n",
              " 't√∫',\n",
              " 'tambi√©n',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'qui√©n',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sart√©n',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " ':',\n",
              " 'Ven',\n",
              " ',',\n",
              " 'ven',\n",
              " ',',\n",
              " 'ven',\n",
              " '[',\n",
              " 'Refr√°n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Wow',\n",
              " ')']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(texto)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3P4OeGn-qo"
      },
      "source": [
        "### Pregunta 1.c (0.5 puntos)\n",
        "¬øQu√© diferencias y similitudes encontrase al comparar la funci√≥n de tokenizaci√≥n creada manualmente por ti contra la implementaci√≥n de NLTK, al tokenizar la letra de la canci√≥n \"Oh, algoritmo\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12BZ29JoFCp"
      },
      "source": [
        "Las principales diferencias son que la tokenizaci√≥n implementada manualmente no guarda simbolos tales como \"?\", \":\",  ni puntos o comas a diferencia de la tokenizaci√≥n implementada con una libreria especifica para aquella tarea. Respecto a las similitudes, se puede observar que ambas implementaciones separan las palabras correctamente, adem√°s en ambas implementaciones se aprecian particularidades tales como que la palabra en ingles \"What¬¥s\" es detectada como dos palabras distintas (What, s)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmUULnB6hWcl"
      },
      "source": [
        "## P2. Stemming y Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskhxOLdpT9q"
      },
      "source": [
        "En esta secci√≥n debera implementar funciones de stemming y stopwords basado en lo visto en clase. En la siguiente celda tiene el corpus que usara en esta secci√≥n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hj07_CmwhYxk"
      },
      "outputs": [],
      "source": [
        "# Corpus en espa√±ol\n",
        "corpus_espanol = [\n",
        "    \"¬øQui√©n quiere que yo quiera lo que creo que quiero?\",\n",
        "    \"Dime qu√© debo cantar\",\n",
        "    \"S√© que lo sabes mejor\"\n",
        "]\n",
        "\n",
        "# Corpus en ingl√©s\n",
        "corpus_ingles = [\n",
        "    \"What's that sitting on your plate?\",\n",
        "    \"Do you want what you've been fed?\",\n",
        "    \"Are you the fish or bait?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xRyOVbVWwJ5"
      },
      "source": [
        "### Pregunta 2.a (0.5 puntos)\n",
        "Implemente una funci√≥n **`get_vocab()`** que extraiga los tokens de un corpus. Puede utilizar la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F-727zL3ptDZ"
      },
      "outputs": [],
      "source": [
        "def get_vocab(corpus):\n",
        "  string = \"\"\n",
        "  if isinstance(corpus, str):\n",
        "    tokens= get_tokens(corpus)\n",
        "  else:\n",
        "    for i in corpus:\n",
        "      string = string + \" \" + i\n",
        "    tokens= get_tokens(string)\n",
        "\n",
        "  return set(tokens)\n",
        "\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  #uniques =set(tokens)\n",
        "  #return uniques\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge2cPS7fqYXy",
        "outputId": "1efddc1a-ddd1-449a-9398-3aad654bf124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['quiero', 'qu√©', 'sabes', 'quiere', 'Qui√©n', 'Dime', 'quiera', 'S√©', 'creo', 'debo', 'mejor', 'que', 'lo', 'yo', 'cantar']\n"
          ]
        }
      ],
      "source": [
        "vocab_espanol = get_vocab(corpus_espanol)\n",
        "print(list(vocab_espanol))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFtzHUbzJqt"
      },
      "source": [
        "Resultado esperado (el orden puede variar):\n",
        "```\n",
        "['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'S√©', 'que', 'quiere', 'quiero', 'sabes', 'Qui√©n', 'quiera', 'qu√©']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apRK_d8uqlSm",
        "outputId": "7659698f-8544-483c-a8b9-b6e5c74c1c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'bait', 've', 'you', 'on', 'sitting', 'What', 'been', 'want', 'Are', 's', 'plate', 'fish', 'your', 'what', 'fed', 'or', 'that', 'Do']\n"
          ]
        }
      ],
      "source": [
        "vocab_ingles = get_vocab(corpus_ingles)\n",
        "print(list(vocab_ingles))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvWMUQq5zPP8"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVjU3cAzDkw"
      },
      "source": [
        "### Pregunta 2.b (0.5 puntos)\n",
        "Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario preprocesado. Explique las reglas de stemming y elecci√≥n de stopwords:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZSeU-rDYbI1"
      },
      "source": [
        "Para el Stemming se eligieron subjifos comunes tanto en ingles como en espa√±ol, los cuales son:\n",
        "\n",
        "- sufijos espa√±ol = [\"ar\", \"er\", \"ir\", \"ado\", \"ido\", \"ci√≥n\", \"si√≥n\", \"es\", \"s\", \"e\", \"o\"]\n",
        "- sufijos_ingles = [\"s\", \"es\", \"ed\", \"ing\", \"ly\", \"s\", ]\n",
        "\n",
        "Para el caso de las Stopword, se eligieron palabras bastante usuales en ambos idiomas, las cuales son:\n",
        "\n",
        "- stop_words_espa√±ol: [\"S√©\", \"y\", \"a\", \"el\", \"en\", \"o\", \"este\", \"s√≠\", \"porque\", \"esta\", \"entre\", \"cuando\",\n",
        "    \"muy\", \"sin\", \"sobre\", \"tambi√©n\", \"me\", \"hasta\", \"hay\", \"donde\", \"quien\",\n",
        "    \"desde\",\"debo\", \"que\", \"yo\", \"qu√©\", \"lo\"]\n",
        "\n",
        "- stop_words_ingles: [\"ve\",\"your\",\"you\",\"the\", \"s\", \"a\", \"an\", \"on\",\"and\",\"or\" ,\"has\", \"do\",\"don¬¥t\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
        "    \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\"\n",
        "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"that\", \"what\", \"Do\", \"What\", \"Are\", \"fed\"]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6iT3h8u9b5zg"
      },
      "outputs": [],
      "source": [
        "def stemming(vocabulario, idioma):\n",
        "  suf_espanol = [\"ar\", \"er\", \"ir\", \"ado\", \"ido\", \"ci√≥n\", \"si√≥n\", \"es\", \"s\", \"e\", \"o\"]\n",
        "  suf_ingles = [\"s\", \"es\", \"ed\", \"ing\", \"ly\", \"s\", ]\n",
        "  voc = []\n",
        "  if idioma == \"espanol\":\n",
        "    sufijo = suf_espanol\n",
        "  else:\n",
        "    sufijo = suf_ingles\n",
        "\n",
        "\n",
        "  for i in vocabulario:\n",
        "      palabra = i\n",
        "      for k in sufijo:\n",
        "        if i.endswith(k):\n",
        "            palabra = re.sub(rf'{k}$', '', i)\n",
        "\n",
        "            break\n",
        "      voc.append(palabra)\n",
        "  return voc\n",
        "\n",
        "def stopWords(vocabulario, idioma):\n",
        "  stop_espanol = [\"S√©\",\"y\", \"a\", \"el\", \"en\", \"o\", \"este\", \"s√≠\", \"porque\", \"esta\", \"entre\", \"cuando\",\n",
        "    \"muy\", \"sin\", \"sobre\", \"tambi√©n\", \"me\", \"hasta\", \"hay\", \"donde\", \"quien\",\n",
        "    \"desde\",\"debo\", \"que\", \"yo\", \"qu√©\", \"lo\"]\n",
        "  stop_ingles = [\"ve\",\"your\",\"you\",\"the\", \"s\",\"a\", \"an\", \"on\",\"and\",\"or\" ,\"has\", \"do\",\"don¬¥t\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
        "    \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\"\n",
        "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"that\", \"what\", \"Do\", \"What\", \"Are\", \"fed\"]\n",
        "\n",
        "  if idioma == \"espanol\":\n",
        "    stopwords = stop_espanol\n",
        "  else:\n",
        "    stopwords = stop_ingles\n",
        "\n",
        "\n",
        "  voc = [i for i in vocabulario if i not in stopwords]\n",
        "\n",
        "\n",
        "\n",
        "  return voc\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "777xbIG2sqy5"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocabulario, idioma):\n",
        "   voc = stopWords(vocabulario, idioma)\n",
        "   voc = stemming(voc, idioma)\n",
        "     \n",
        "   return voc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpyRoYZzgbhh",
        "outputId": "dd146be2-85e9-49d6-bd2c-39b6e1e68057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario procesado en espa√±ol: ['quier', 'sab', 'quier', 'Qui√©n', 'Dim', 'quiera', 'cre', 'mejor', 'cant'] \n",
            "\n",
            "Vocabulario procesado en ingl√©s: ['bait', 'sitt', 'want', 'plate', 'fish'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Aplicar preprocesamiento a los vocabularios de ejemplo con NLTK\n",
        "vocab_procesado_espanol = pre_processing(vocab_espanol, 'espanol')\n",
        "vocab_procesado_ingles = pre_processing(vocab_ingles, 'ingles')\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Vocabulario procesado en espa√±ol:\", vocab_procesado_espanol, \"\\n\")\n",
        "print(\"Vocabulario procesado en ingl√©s:\", vocab_procesado_ingles, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajmn1HaNhZE9"
      },
      "source": [
        "## P3. Bag of Words (0.5 puntos)\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vT0XQM2Ghlvy"
      },
      "outputs": [],
      "source": [
        "d0 = 'El p√°jaro come semillas'\n",
        "d1 = 'El p√°jaro se despierta y canta'\n",
        "d2 = 'El p√°jaro canta y come semillas'\n",
        "d3 = 'El pez come y nada en el agua'\n",
        "d4 = 'El pez empieza a nadar'\n",
        "d5 = 'El pez come alimento'\n",
        "corpus = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOOz1Su2ATf"
      },
      "source": [
        "El objetivo da las siguientes secciones es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica **TF-IDF**.\n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es la de **Bag of Words**, m√©todo mediante el cual se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funci√≥n **`bag_of_words()`**, que recibe como input un arreglo de documentos y devuelve un dataframe de pandas con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representan las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el BoW de un documento.\n",
        "\n",
        "***Disclaimer: el orden de los resultados pueden variar.***\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente corpus:\n",
        "\n",
        "```\n",
        "corpus = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1xkXqv5Hek_",
        "outputId": "def5c18e-6403-4871-8780-c7e31f0eaf3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 {'come', 'semillas', 'p√°jaro', 'El'}\n",
            "1 {'se', 'y', 'canta', 'p√°jaro', 'El', 'despierta'}\n",
            "2 {'canta', 'y', 'p√°jaro', 'El', 'come', 'semillas'}\n",
            "3 {'y', 'El', 'come', 'en', 'el', 'pez', 'agua', 'nada'}\n",
            "4 {'a', 'El', 'pez', 'empieza', 'nadar'}\n",
            "5 {'pez', 'come', 'alimento', 'El'}\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(corpus):\n",
        "  print(i , get_vocab(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_njmcRPM2GpV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENCbDO8s_ls"
      },
      "source": [
        "Implementar funci√≥n `bag_of_words()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C_eRRUvD2ChD"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(corpus):\n",
        "    columns = get_vocab(corpus)\n",
        "    columns = list(columns)\n",
        "    dataset = pd.DataFrame(columns = columns)\n",
        "    for i, doc in enumerate(corpus):\n",
        "      dic = {}\n",
        "      palabras = get_tokens(doc)\n",
        "\n",
        "      for pal in palabras:\n",
        "          dic[pal] = columns.count(pal)\n",
        "\n",
        "\n",
        "      new_row = pd.DataFrame(dic, index=[f\"d{i}\"])\n",
        "      dataset = pd.concat([dataset, new_row])\n",
        "    dataset = dataset.fillna(0)\n",
        "    return dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "jWZyXGra2FOw",
        "outputId": "8dc30ceb-cea0-4bcc-d448-05199e5c4c26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_51080/2830846725.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset = dataset.fillna(0)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>se</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>El</th>\n",
              "      <th>a</th>\n",
              "      <th>come</th>\n",
              "      <th>alimento</th>\n",
              "      <th>despierta</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>semillas</th>\n",
              "      <th>pez</th>\n",
              "      <th>agua</th>\n",
              "      <th>nada</th>\n",
              "      <th>empieza</th>\n",
              "      <th>nadar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    se  y  canta  p√°jaro  El  a  come  alimento  despierta  en  el  semillas  \\\n",
              "d0   0  0      0       1   1  0     1         0          0   0   0         1   \n",
              "d1   1  1      1       1   1  0     0         0          1   0   0         0   \n",
              "d2   0  1      1       1   1  0     1         0          0   0   0         1   \n",
              "d3   0  1      0       0   1  0     1         0          0   1   1         0   \n",
              "d4   0  0      0       0   1  1     0         0          0   0   0         0   \n",
              "d5   0  0      0       0   1  0     1         1          0   0   0         0   \n",
              "\n",
              "    pez  agua  nada  empieza  nadar  \n",
              "d0    0     0     0        0      0  \n",
              "d1    0     0     0        0      0  \n",
              "d2    0     0     0        0      0  \n",
              "d3    1     1     1        0      0  \n",
              "d4    1     0     0        1      1  \n",
              "d5    1     0     0        0      0  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(corpus)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEA2Ic2sLlh"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMv3UZdRhgqT"
      },
      "source": [
        "## P4. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oxW5CZjhoE9"
      },
      "source": [
        "### 4.a TF (0.25 puntos)\n",
        "\n",
        "Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia $\\max_i({\\text{tf}_{i,j}})$, donde\n",
        "$i$ corresponde al √≠ndice de las filas (BoW) y $j$ al de las columnas (palabras). Es decir, dividir cada BoW sobre la cantidad de veces de la palabra que aparezca m√°s veces en ese vector.\n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{\\max_i({\\text{tf}_{i,j})}}$$\n",
        "\n",
        "Implemente la funci√≥n `calc_tf(dataset_bow)`, que entrega la matriz de TF normalizada del BoW del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qQhnJuuShmR5"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow):\n",
        "      # Obtener el valor m√°ximo de cada fila\n",
        "    max_row = dataset_bow.max(axis=1)\n",
        "\n",
        "    # Dividir cada fila por su m√°ximo\n",
        "    dataset = dataset_bow.div(max_row, axis=0)\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    return dataset\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "urDKFQVu2p3V",
        "outputId": "702eb5aa-e28b-4896-9526-2c581fcac568"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>se</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>El</th>\n",
              "      <th>a</th>\n",
              "      <th>come</th>\n",
              "      <th>alimento</th>\n",
              "      <th>despierta</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>semillas</th>\n",
              "      <th>pez</th>\n",
              "      <th>agua</th>\n",
              "      <th>nada</th>\n",
              "      <th>empieza</th>\n",
              "      <th>nadar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     se    y  canta  p√°jaro   El    a  come  alimento  despierta   en   el  \\\n",
              "d0  0.0  0.0    0.0     1.0  1.0  0.0   1.0       0.0        0.0  0.0  0.0   \n",
              "d1  1.0  1.0    1.0     1.0  1.0  0.0   0.0       0.0        1.0  0.0  0.0   \n",
              "d2  0.0  1.0    1.0     1.0  1.0  0.0   1.0       0.0        0.0  0.0  0.0   \n",
              "d3  0.0  1.0    0.0     0.0  1.0  0.0   1.0       0.0        0.0  1.0  1.0   \n",
              "d4  0.0  0.0    0.0     0.0  1.0  1.0   0.0       0.0        0.0  0.0  0.0   \n",
              "d5  0.0  0.0    0.0     0.0  1.0  0.0   1.0       1.0        0.0  0.0  0.0   \n",
              "\n",
              "    semillas  pez  agua  nada  empieza  nadar  \n",
              "d0       1.0  0.0   0.0   0.0      0.0    0.0  \n",
              "d1       0.0  0.0   0.0   0.0      0.0    0.0  \n",
              "d2       1.0  0.0   0.0   0.0      0.0    0.0  \n",
              "d3       0.0  1.0   1.0   1.0      0.0    0.0  \n",
              "d4       0.0  1.0   0.0   0.0      1.0    1.0  \n",
              "d5       0.0  1.0   0.0   0.0      0.0    0.0  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swo3ZjwVtZlq"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh2bFyHFhpbM"
      },
      "source": [
        "### 4.b IDF (0.5 puntos)\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. √âsta debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el c√°lculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $\\text{idf}_{t_i} = \\log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ n√∫mero de documentos que contienen la palabra $t_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tGLjlSY02usu"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qoU4AIrm2sDT"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    words = dataset_bow.columns\n",
        "    dic = {}\n",
        "    for i in words:\n",
        "      dic[i] = math.log10(len(dataset_bow)/dataset_bow[dataset_bow[i] != 0][i].value_counts().sum())\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    return dic\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXPErPdw2uQx",
        "outputId": "ffd26a1c-64a6-40ab-e0c7-355003beaff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'se': 0.7781512503836436,\n",
              " 'y': 0.3010299956639812,\n",
              " 'canta': 0.47712125471966244,\n",
              " 'p√°jaro': 0.3010299956639812,\n",
              " 'El': 0.0,\n",
              " 'a': 0.7781512503836436,\n",
              " 'come': 0.17609125905568124,\n",
              " 'alimento': 0.7781512503836436,\n",
              " 'despierta': 0.7781512503836436,\n",
              " 'en': 0.7781512503836436,\n",
              " 'el': 0.7781512503836436,\n",
              " 'semillas': 0.47712125471966244,\n",
              " 'pez': 0.3010299956639812,\n",
              " 'agua': 0.7781512503836436,\n",
              " 'nada': 0.7781512503836436,\n",
              " 'empieza': 0.7781512503836436,\n",
              " 'nadar': 0.7781512503836436}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmp5lXdquAD1"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "{'El': 0.0,\n",
        " 'p√°jaro': 0.3010299956639812,\n",
        " 'despierta': 0.7781512503836436,\n",
        " 'el': 0.7781512503836436,\n",
        " 'come': 0.17609125905568124,\n",
        " 'a': 0.7781512503836436,\n",
        " 'nadar': 0.7781512503836436,\n",
        " 'se': 0.7781512503836436,\n",
        " 'en': 0.7781512503836436,\n",
        " 'y': 0.3010299956639812,\n",
        " 'alimento': 0.7781512503836436,\n",
        " 'semillas': 0.47712125471966244,\n",
        " 'pez': 0.3010299956639812,\n",
        " 'empieza': 0.7781512503836436,\n",
        " 'canta': 0.47712125471966244,\n",
        " 'agua': 0.7781512503836436,\n",
        " 'nada': 0.7781512503836436}\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC-_vwiV20XL"
      },
      "source": [
        "### 4.c TF-IDF (0.25 puntos)\n",
        "Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "004IuUyt23_6"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "\n",
        "\n",
        "    for word in tf.columns:\n",
        "      tf.loc[tf[word]> 0, word] = idf[word]\n",
        "\n",
        "    return tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "KXjP0S3626dw",
        "outputId": "07f96a06-44fd-43f2-99ca-c021818f9ab7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>se</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>El</th>\n",
              "      <th>a</th>\n",
              "      <th>come</th>\n",
              "      <th>alimento</th>\n",
              "      <th>despierta</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>semillas</th>\n",
              "      <th>pez</th>\n",
              "      <th>agua</th>\n",
              "      <th>nada</th>\n",
              "      <th>empieza</th>\n",
              "      <th>nadar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          se        y     canta   p√°jaro   El         a      come  alimento  \\\n",
              "d0  0.000000  0.00000  0.000000  0.30103  0.0  0.000000  0.176091  0.000000   \n",
              "d1  0.778151  0.30103  0.477121  0.30103  0.0  0.000000  0.000000  0.000000   \n",
              "d2  0.000000  0.30103  0.477121  0.30103  0.0  0.000000  0.176091  0.000000   \n",
              "d3  0.000000  0.30103  0.000000  0.00000  0.0  0.000000  0.176091  0.000000   \n",
              "d4  0.000000  0.00000  0.000000  0.00000  0.0  0.778151  0.000000  0.000000   \n",
              "d5  0.000000  0.00000  0.000000  0.00000  0.0  0.000000  0.176091  0.778151   \n",
              "\n",
              "    despierta        en        el  semillas      pez      agua      nada  \\\n",
              "d0   0.000000  0.000000  0.000000  0.477121  0.00000  0.000000  0.000000   \n",
              "d1   0.778151  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "d2   0.000000  0.000000  0.000000  0.477121  0.00000  0.000000  0.000000   \n",
              "d3   0.000000  0.778151  0.778151  0.000000  0.30103  0.778151  0.778151   \n",
              "d4   0.000000  0.000000  0.000000  0.000000  0.30103  0.000000  0.000000   \n",
              "d5   0.000000  0.000000  0.000000  0.000000  0.30103  0.000000  0.000000   \n",
              "\n",
              "     empieza     nadar  \n",
              "d0  0.000000  0.000000  \n",
              "d1  0.000000  0.000000  \n",
              "d2  0.000000  0.000000  \n",
              "d3  0.000000  0.000000  \n",
              "d4  0.778151  0.778151  \n",
              "d5  0.000000  0.000000  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNTa32IsuLWl"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |       el |     come |        a |    nadar |       se |       en |       y |   alimento |   semillas |     pez |   empieza |    canta |     agua |     nada |\n",
        "|:---|-----:|---------:|------------:|---------:|---------:|---------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|----------:|---------:|---------:|---------:|\n",
        "| d0 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0        |   0.477121 | 0       |  0        | 0        | 0        | 0        |\n",
        "| d1 |    0 |  0.30103 |    0.778151 | 0        | 0        | 0        | 0        | 0.778151 | 0        | 0.30103 |   0        |   0        | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d2 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0.30103 |   0        |   0.477121 | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d3 |    0 |  0       |    0        | 0.778151 | 0.176091 | 0        | 0        | 0        | 0.778151 | 0.30103 |   0        |   0        | 0.30103 |  0        | 0        | 0.778151 | 0.778151 |\n",
        "| d4 |    0 |  0       |    0        | 0        | 0        | 0.778151 | 0.778151 | 0        | 0        | 0       |   0        |   0        | 0.30103 |  0.778151 | 0        | 0        | 0        |\n",
        "| d5 |    0 |  0       |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0.778151 |   0        | 0.30103 |  0        | 0        | 0        | 0        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8sQEjVshjQ7"
      },
      "source": [
        "## P5. Cosine-similarity (0.25 puntos)\n",
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica.\n",
        "\n",
        "Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos. Concluya cu√°les son los dos documentos m√°s similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_68mo-BLhmuV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    # Calcula el producto punto entre los dos vectores\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    # Calcula la norma (magnitud) de cada vector\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "    # Calcula la similitud coseno\n",
        "    similarity = dot_product / (norm_v1 * norm_v2)\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5z-23CN2_lU",
        "outputId": "6798f54e-69dc-40c6-ca35-d2d4995fe168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El p√°jaro come semillas\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.7233435041520414 \n",
            "\n",
            "El p√°jaro se despierta y canta\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.39320101823128945 \n",
            "\n",
            "El p√°jaro canta y come semillas\n",
            "> Mas similar: El p√°jaro come semillas\n",
            "> Similitud: 0.7233435041520414 \n",
            "\n",
            "El pez come y nada en el agua\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.09171890791406168 \n",
            "\n",
            "El pez empieza a nadar\n",
            "> Mas similar: El pez come alimento\n",
            "> Similitud: 0.07695078406752713 \n",
            "\n",
            "El pez come alimento\n",
            "> Mas similar: El pez come y nada en el agua\n",
            "> Similitud: 0.08787900372173231 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n",
        "\n",
        "for i in range(6):\n",
        "  mask = [k != i for k in range(6)]\n",
        "  j = np.argmax(similarity_matrix[i][mask])\n",
        "\n",
        "  print(corpus[i])\n",
        "  print(\"> Mas similar:\", np.array(corpus)[mask][j])\n",
        "  print(\"> Similitud:\", similarity_matrix[i][mask][j], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71oH4JHXulGQ"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "El p√°jaro come semillas\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El p√°jaro se despierta y canta\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.39320101823128945\n",
        "\n",
        "El p√°jaro canta y come semillas\n",
        "> Mas similar: El p√°jaro come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pez come y nada en el agua\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.09171890791406168\n",
        "\n",
        "El pez empieza a nadar\n",
        "> Mas similar: El pez come alimento\n",
        "> Similitud: 0.07695078406752713\n",
        "\n",
        "El pez come alimento\n",
        "> Mas similar: El pez come y nada en el agua\n",
        "> Similitud: 0.0878790037217323\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDZln45jfjMf"
      },
      "source": [
        "## P6 N-gramas (0.75 punto)\n",
        "\n",
        "En esta secci√≥n debera determinar los n-gramas del la cancion \"Oh algoritmo\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7duKoBvlSgg"
      },
      "source": [
        "### 6.a Corpus de entrenamiento y test (0.25 puntos)\n",
        "\n",
        "En esta subsecci√≥n debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juDVurFfl3eZ",
        "outputId": "4c6398a1-ed7b-45ed-cdf7-c5fcd6ffb4c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canci√≥n\n",
            "¬øQu√© algoritmo la pari√≥?\n",
            "Me pregunto si fui yo\n",
            "¬øLa elegiste o te eligi√≥?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con √âl\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedr√≠o es un cauce vac√≠o\n",
            "Un barco que no tiene r√≠o\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, t√∫ tambi√©n\n",
            "Pero no queda claro qui√©n\n",
            "Tiene del mango a la sart√©n\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurri√≥ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYCw0AqOmlzD"
      },
      "source": [
        "Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "C88f9aVil9d_"
      },
      "outputs": [],
      "source": [
        "def get_sentences(texto):\n",
        "    # Divide el texto en l√≠neas\n",
        "    lineas = texto.split('\\n')\n",
        "    # Filtra las l√≠neas que contienen al menos una palabra\n",
        "    oraciones_limpias = [linea.strip() for linea in lineas if len(linea.strip().split()) >= 1]\n",
        "    return oraciones_limpias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbZ8EhgHmR2c",
        "outputId": "c4b6502e-889a-4339-ee58-1b427867c405"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 1: Nora Erez]',\n",
              " \"Wait, what's that money that you spent?\",\n",
              " \"What's that sitting on your plate?\",\n",
              " \"Do you want what you've been fed?\",\n",
              " 'Are you the fish or bait?',\n",
              " \"Mmm, I'm on the top of the roof and I feel like a jail\",\n",
              " 'Rather not pay the bail',\n",
              " 'To dangerous people with blood on their faces',\n",
              " \"So I'm sharing a cell with the masses\",\n",
              " 'The underground always strive for the main',\n",
              " \"Streaming like Grande's big-ass ring\",\n",
              " \"Screaming: I'll write you out my will\",\n",
              " 'Conscious is free, but not the will',\n",
              " 'Conscious is free, but not the will',\n",
              " 'You might also like',\n",
              " 'Amor al Arte',\n",
              " 'Jorge Drexler',\n",
              " 'Tinta y Tiempo',\n",
              " 'Jorge Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge Drexler',\n",
              " '[Pre-Estribillo: Nora Erez]',\n",
              " 'So if you want me to want what I believe that I want',\n",
              " 'Can I choose to quit?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 2: Jorge Drexler]',\n",
              " 'Por ejemplo, esta canci√≥n',\n",
              " '¬øQu√© algoritmo la pari√≥?',\n",
              " 'Me pregunto si fui yo',\n",
              " '¬øLa elegiste o te eligi√≥?',\n",
              " '[Verso 3: Jorge Drexler]',\n",
              " 'Dios era la letra chica al final del papel',\n",
              " 'Ya no contamos con √âl',\n",
              " 'Fin de la Luna de miel',\n",
              " 'Y el libre albedr√≠o es un cauce vac√≠o',\n",
              " 'Un barco que no tiene r√≠o',\n",
              " 'Ni timonel',\n",
              " '[Verso 4: Jorge Drexler]',\n",
              " 'Todos aplauden, t√∫ tambi√©n',\n",
              " 'Pero no queda claro qui√©n',\n",
              " 'Tiene del mango a la sart√©n',\n",
              " 'Del sacrificio',\n",
              " 'Piel o silicio',\n",
              " 'Y el precipicio',\n",
              " 'Dice: Ven, ven, ven',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Wow)']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oraciones_limpias = get_sentences(texto)\n",
        "oraciones_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEBzcR6Ym0Us"
      },
      "source": [
        "Deber√≠a obtener en total 87 oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pDN1vGEmwRQ",
        "outputId": "bdecd9e4-4d9e-4297-9319-8f938fc726ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(oraciones_limpias) == 87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9dq8omm7cD"
      },
      "source": [
        "Ahora definiremos el conjunto de entrenamiento y prueba para las oraciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHoR_-inEK1",
        "outputId": "c28b779e-ab7e-4c55-b061-86701fadacba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69, 18)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split = int(len(oraciones_limpias) * 0.8)\n",
        "train_corpus = oraciones_limpias[:split]\n",
        "test_corpus = oraciones_limpias[split:]\n",
        "\n",
        "len(train_corpus), len(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csdw0qNsmjTF"
      },
      "source": [
        "### 6.b Estimaci√≥n de N-gramas (0.5 puntos)\n",
        "\n",
        "Defina una funci√≥n que reciba una lista de oraciones de un corpus y un N que indique el tama√±o de los N-gramas. La funci√≥n debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe a√±adir un token especial al inicio o final de cada oraci√≥n seg√∫n corresponda (ver clases del curso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "#import nltk\n",
        "#nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Lbrl3WVnmRzj"
      },
      "outputs": [],
      "source": [
        "def n_grams(corpus, n=3):\n",
        "    # Define an empty dictionary to store n-gram frequencies\n",
        "    n_grams_freq = {}\n",
        "\n",
        "    # Iterate through each sentence in the corpus\n",
        "    for sentence in corpus:\n",
        "\n",
        "        modified_sentence = ' '.join(['*'] * (n-1) + [sentence] + ['*'] * (n-1))\n",
        "        tokens = word_tokenize(modified_sentence)\n",
        "        # Loop through the tokens and create n-grams\n",
        "        for i in range(len(tokens)-n+1):\n",
        "            # Create a tuple for the n-gram\n",
        "            ngram = tuple(tokens[i:i+n])\n",
        "            \n",
        "            # Check if the n-gram exists in the dictionary\n",
        "            if ngram in n_grams_freq:\n",
        "                # Increment the count if it exists\n",
        "                n_grams_freq[ngram] += 1\n",
        "            else:\n",
        "                # Initialize the count to 1 for new n-grams\n",
        "                n_grams_freq[ngram] = 1\n",
        "\n",
        "    return dict(sorted(n_grams_freq.items(), key=lambda x: x[1], reverse=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mAoYncsp3C7u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('que',): 38,\n",
              " ('?',): 18,\n",
              " ('yo',): 14,\n",
              " ('lo',): 13,\n",
              " (',',): 11,\n",
              " (':',): 11,\n",
              " ('¬øQui√©n',): 11,\n",
              " ('quiere',): 11,\n",
              " ('quiera',): 11,\n",
              " ('creo',): 11,\n",
              " ('quiero',): 11,\n",
              " ('[',): 10,\n",
              " (']',): 10,\n",
              " ('Jorge',): 10,\n",
              " ('Drexler',): 10,\n",
              " ('the',): 8,\n",
              " ('I',): 7,\n",
              " ('you',): 6,\n",
              " ('Verso',): 4,\n",
              " ('that',): 4,\n",
              " ('want',): 4,\n",
              " ('la',): 4,\n",
              " ('de',): 3,\n",
              " ('Nora',): 3,\n",
              " ('Erez',): 3,\n",
              " ('Dime',): 3,\n",
              " ('qu√©',): 3,\n",
              " ('debo',): 3,\n",
              " ('cantar',): 3,\n",
              " ('algoritmo',): 3,\n",
              " ('what',): 3,\n",
              " (\"'s\",): 3,\n",
              " ('on',): 3,\n",
              " ('like',): 3,\n",
              " ('a',): 3,\n",
              " ('not',): 3,\n",
              " ('will',): 3,\n",
              " ('no',): 3,\n",
              " ('Refr√°n',): 2,\n",
              " ('Estribillo',): 2,\n",
              " ('Oh',): 2,\n",
              " ('S√©',): 2,\n",
              " ('sabes',): 2,\n",
              " ('mejor',): 2,\n",
              " ('Incluso',): 2,\n",
              " ('mismo',): 2,\n",
              " (\"'m\",): 2,\n",
              " ('with',): 2,\n",
              " ('So',): 2,\n",
              " ('Conscious',): 2,\n",
              " ('is',): 2,\n",
              " ('free',): 2,\n",
              " ('but',): 2,\n",
              " ('al',): 2,\n",
              " ('to',): 2,\n",
              " ('o',): 2,\n",
              " ('del',): 2,\n",
              " ('Y',): 2,\n",
              " ('el',): 2,\n",
              " ('ven',): 2,\n",
              " ('Letra',): 1,\n",
              " ('``',): 1,\n",
              " ('¬°Oh',): 1,\n",
              " ('Algoritmo',): 1,\n",
              " ('!',): 1,\n",
              " (\"''\",): 1,\n",
              " ('ft.',): 1,\n",
              " ('1',): 1,\n",
              " ('Wait',): 1,\n",
              " ('money',): 1,\n",
              " ('spent',): 1,\n",
              " ('What',): 1,\n",
              " ('sitting',): 1,\n",
              " ('your',): 1,\n",
              " ('plate',): 1,\n",
              " ('Do',): 1,\n",
              " (\"'ve\",): 1,\n",
              " ('been',): 1,\n",
              " ('fed',): 1,\n",
              " ('Are',): 1,\n",
              " ('fish',): 1,\n",
              " ('or',): 1,\n",
              " ('bait',): 1,\n",
              " ('Mmm',): 1,\n",
              " ('top',): 1,\n",
              " ('of',): 1,\n",
              " ('roof',): 1,\n",
              " ('and',): 1,\n",
              " ('feel',): 1,\n",
              " ('jail',): 1,\n",
              " ('Rather',): 1,\n",
              " ('pay',): 1,\n",
              " ('bail',): 1,\n",
              " ('To',): 1,\n",
              " ('dangerous',): 1,\n",
              " ('people',): 1,\n",
              " ('blood',): 1,\n",
              " ('their',): 1,\n",
              " ('faces',): 1,\n",
              " ('sharing',): 1,\n",
              " ('cell',): 1,\n",
              " ('masses',): 1,\n",
              " ('The',): 1,\n",
              " ('underground',): 1,\n",
              " ('always',): 1,\n",
              " ('strive',): 1,\n",
              " ('for',): 1,\n",
              " ('main',): 1,\n",
              " ('Streaming',): 1,\n",
              " ('Grande',): 1,\n",
              " ('big-ass',): 1,\n",
              " ('ring',): 1,\n",
              " ('Screaming',): 1,\n",
              " (\"'ll\",): 1,\n",
              " ('write',): 1,\n",
              " ('out',): 1,\n",
              " ('my',): 1,\n",
              " ('You',): 1,\n",
              " ('might',): 1,\n",
              " ('also',): 1,\n",
              " ('Amor',): 1,\n",
              " ('Arte',): 1,\n",
              " ('Tinta',): 1,\n",
              " ('y',): 1,\n",
              " ('Tiempo',): 1,\n",
              " ('Asilo',): 1,\n",
              " ('Pre-Estribillo',): 1,\n",
              " ('if',): 1,\n",
              " ('me',): 1,\n",
              " ('believe',): 1,\n",
              " ('Can',): 1,\n",
              " ('choose',): 1,\n",
              " ('quit',): 1,\n",
              " ('2',): 1,\n",
              " ('Por',): 1,\n",
              " ('ejemplo',): 1,\n",
              " ('esta',): 1,\n",
              " ('canci√≥n',): 1,\n",
              " ('¬øQu√©',): 1,\n",
              " ('pari√≥',): 1,\n",
              " ('Me',): 1,\n",
              " ('pregunto',): 1,\n",
              " ('si',): 1,\n",
              " ('fui',): 1,\n",
              " ('¬øLa',): 1,\n",
              " ('elegiste',): 1,\n",
              " ('te',): 1,\n",
              " ('eligi√≥',): 1,\n",
              " ('3',): 1,\n",
              " ('Dios',): 1,\n",
              " ('era',): 1,\n",
              " ('letra',): 1,\n",
              " ('chica',): 1,\n",
              " ('final',): 1,\n",
              " ('papel',): 1,\n",
              " ('Ya',): 1,\n",
              " ('contamos',): 1,\n",
              " ('con',): 1,\n",
              " ('√âl',): 1,\n",
              " ('Fin',): 1,\n",
              " ('Luna',): 1,\n",
              " ('miel',): 1,\n",
              " ('libre',): 1,\n",
              " ('albedr√≠o',): 1,\n",
              " ('es',): 1,\n",
              " ('un',): 1,\n",
              " ('cauce',): 1,\n",
              " ('vac√≠o',): 1,\n",
              " ('Un',): 1,\n",
              " ('barco',): 1,\n",
              " ('tiene',): 1,\n",
              " ('r√≠o',): 1,\n",
              " ('Ni',): 1,\n",
              " ('timonel',): 1,\n",
              " ('4',): 1,\n",
              " ('Todos',): 1,\n",
              " ('aplauden',): 1,\n",
              " ('t√∫',): 1,\n",
              " ('tambi√©n',): 1,\n",
              " ('Pero',): 1,\n",
              " ('queda',): 1,\n",
              " ('claro',): 1,\n",
              " ('qui√©n',): 1,\n",
              " ('Tiene',): 1,\n",
              " ('mango',): 1,\n",
              " ('sart√©n',): 1,\n",
              " ('Del',): 1,\n",
              " ('sacrificio',): 1,\n",
              " ('Piel',): 1,\n",
              " ('silicio',): 1,\n",
              " ('precipicio',): 1,\n",
              " ('Dice',): 1,\n",
              " ('Ven',): 1,\n",
              " ('(',): 1,\n",
              " (')',): 1}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "A8XDEuRF3Grx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('?', '*'): 18,\n",
              " ('que', 'yo'): 13,\n",
              " ('*', '¬øQui√©n'): 11,\n",
              " ('¬øQui√©n', 'quiere'): 11,\n",
              " ('quiere', 'que'): 11,\n",
              " ('yo', 'quiera'): 11,\n",
              " ('quiera', 'lo'): 11,\n",
              " ('lo', 'que'): 11,\n",
              " ('que', 'creo'): 11,\n",
              " ('creo', 'que'): 11,\n",
              " ('que', 'quiero'): 11,\n",
              " ('quiero', '?'): 11,\n",
              " ('*', '['): 10,\n",
              " (']', '*'): 10,\n",
              " ('Jorge', 'Drexler'): 10,\n",
              " (':', 'Jorge'): 7,\n",
              " ('Drexler', ']'): 7,\n",
              " ('[', 'Verso'): 4,\n",
              " ('Nora', 'Erez'): 3,\n",
              " ('Erez', ']'): 3,\n",
              " ('Dime', 'qu√©'): 3,\n",
              " ('qu√©', 'debo'): 3,\n",
              " ('debo', 'cantar'): 3,\n",
              " ('will', '*'): 3,\n",
              " ('*', 'Jorge'): 3,\n",
              " ('Drexler', '*'): 3,\n",
              " ('[', 'Refr√°n'): 2,\n",
              " ('Refr√°n', ':'): 2,\n",
              " ('[', 'Estribillo'): 2,\n",
              " ('Estribillo', ':'): 2,\n",
              " ('*', 'Dime'): 2,\n",
              " ('cantar', '*'): 2,\n",
              " ('*', 'Oh'): 2,\n",
              " ('Oh', ','): 2,\n",
              " (',', 'algoritmo'): 2,\n",
              " ('algoritmo', '*'): 2,\n",
              " ('*', 'S√©'): 2,\n",
              " ('S√©', 'que'): 2,\n",
              " ('que', 'lo'): 2,\n",
              " ('lo', 'sabes'): 2,\n",
              " ('sabes', 'mejor'): 2,\n",
              " ('mejor', '*'): 2,\n",
              " ('*', 'Incluso'): 2,\n",
              " ('Incluso', 'que'): 2,\n",
              " ('yo', 'mismo'): 2,\n",
              " ('mismo', '*'): 2,\n",
              " (':', 'Nora'): 2,\n",
              " (\"'s\", 'that'): 2,\n",
              " ('you', 'want'): 2,\n",
              " ('want', 'what'): 2,\n",
              " ('I', \"'m\"): 2,\n",
              " ('*', 'So'): 2,\n",
              " ('*', 'Conscious'): 2,\n",
              " ('Conscious', 'is'): 2,\n",
              " ('is', 'free'): 2,\n",
              " ('free', ','): 2,\n",
              " (',', 'but'): 2,\n",
              " ('but', 'not'): 2,\n",
              " ('not', 'the'): 2,\n",
              " ('the', 'will'): 2,\n",
              " ('*', 'Y'): 2,\n",
              " ('Y', 'el'): 2,\n",
              " (',', 'ven'): 2,\n",
              " ('[', 'Letra'): 1,\n",
              " ('Letra', 'de'): 1,\n",
              " ('de', '``'): 1,\n",
              " ('``', '¬°Oh'): 1,\n",
              " ('¬°Oh', ','): 1,\n",
              " (',', 'Algoritmo'): 1,\n",
              " ('Algoritmo', '!'): 1,\n",
              " ('!', \"''\"): 1,\n",
              " (\"''\", 'ft.'): 1,\n",
              " ('ft.', 'Nora'): 1,\n",
              " ('Verso', '1'): 1,\n",
              " ('1', ':'): 1,\n",
              " ('*', 'Wait'): 1,\n",
              " ('Wait', ','): 1,\n",
              " (',', 'what'): 1,\n",
              " ('what', \"'s\"): 1,\n",
              " ('that', 'money'): 1,\n",
              " ('money', 'that'): 1,\n",
              " ('that', 'you'): 1,\n",
              " ('you', 'spent'): 1,\n",
              " ('spent', '?'): 1,\n",
              " ('*', 'What'): 1,\n",
              " ('What', \"'s\"): 1,\n",
              " ('that', 'sitting'): 1,\n",
              " ('sitting', 'on'): 1,\n",
              " ('on', 'your'): 1,\n",
              " ('your', 'plate'): 1,\n",
              " ('plate', '?'): 1,\n",
              " ('*', 'Do'): 1,\n",
              " ('Do', 'you'): 1,\n",
              " ('what', 'you'): 1,\n",
              " ('you', \"'ve\"): 1,\n",
              " (\"'ve\", 'been'): 1,\n",
              " ('been', 'fed'): 1,\n",
              " ('fed', '?'): 1,\n",
              " ('*', 'Are'): 1,\n",
              " ('Are', 'you'): 1,\n",
              " ('you', 'the'): 1,\n",
              " ('the', 'fish'): 1,\n",
              " ('fish', 'or'): 1,\n",
              " ('or', 'bait'): 1,\n",
              " ('bait', '?'): 1,\n",
              " ('*', 'Mmm'): 1,\n",
              " ('Mmm', ','): 1,\n",
              " (',', 'I'): 1,\n",
              " (\"'m\", 'on'): 1,\n",
              " ('on', 'the'): 1,\n",
              " ('the', 'top'): 1,\n",
              " ('top', 'of'): 1,\n",
              " ('of', 'the'): 1,\n",
              " ('the', 'roof'): 1,\n",
              " ('roof', 'and'): 1,\n",
              " ('and', 'I'): 1,\n",
              " ('I', 'feel'): 1,\n",
              " ('feel', 'like'): 1,\n",
              " ('like', 'a'): 1,\n",
              " ('a', 'jail'): 1,\n",
              " ('jail', '*'): 1,\n",
              " ('*', 'Rather'): 1,\n",
              " ('Rather', 'not'): 1,\n",
              " ('not', 'pay'): 1,\n",
              " ('pay', 'the'): 1,\n",
              " ('the', 'bail'): 1,\n",
              " ('bail', '*'): 1,\n",
              " ('*', 'To'): 1,\n",
              " ('To', 'dangerous'): 1,\n",
              " ('dangerous', 'people'): 1,\n",
              " ('people', 'with'): 1,\n",
              " ('with', 'blood'): 1,\n",
              " ('blood', 'on'): 1,\n",
              " ('on', 'their'): 1,\n",
              " ('their', 'faces'): 1,\n",
              " ('faces', '*'): 1,\n",
              " ('So', 'I'): 1,\n",
              " (\"'m\", 'sharing'): 1,\n",
              " ('sharing', 'a'): 1,\n",
              " ('a', 'cell'): 1,\n",
              " ('cell', 'with'): 1,\n",
              " ('with', 'the'): 1,\n",
              " ('the', 'masses'): 1,\n",
              " ('masses', '*'): 1,\n",
              " ('*', 'The'): 1,\n",
              " ('The', 'underground'): 1,\n",
              " ('underground', 'always'): 1,\n",
              " ('always', 'strive'): 1,\n",
              " ('strive', 'for'): 1,\n",
              " ('for', 'the'): 1,\n",
              " ('the', 'main'): 1,\n",
              " ('main', '*'): 1,\n",
              " ('*', 'Streaming'): 1,\n",
              " ('Streaming', 'like'): 1,\n",
              " ('like', 'Grande'): 1,\n",
              " ('Grande', \"'s\"): 1,\n",
              " (\"'s\", 'big-ass'): 1,\n",
              " ('big-ass', 'ring'): 1,\n",
              " ('ring', '*'): 1,\n",
              " ('*', 'Screaming'): 1,\n",
              " ('Screaming', ':'): 1,\n",
              " (':', 'I'): 1,\n",
              " ('I', \"'ll\"): 1,\n",
              " (\"'ll\", 'write'): 1,\n",
              " ('write', 'you'): 1,\n",
              " ('you', 'out'): 1,\n",
              " ('out', 'my'): 1,\n",
              " ('my', 'will'): 1,\n",
              " ('*', 'You'): 1,\n",
              " ('You', 'might'): 1,\n",
              " ('might', 'also'): 1,\n",
              " ('also', 'like'): 1,\n",
              " ('like', '*'): 1,\n",
              " ('*', 'Amor'): 1,\n",
              " ('Amor', 'al'): 1,\n",
              " ('al', 'Arte'): 1,\n",
              " ('Arte', '*'): 1,\n",
              " ('*', 'Tinta'): 1,\n",
              " ('Tinta', 'y'): 1,\n",
              " ('y', 'Tiempo'): 1,\n",
              " ('Tiempo', '*'): 1,\n",
              " ('*', 'Asilo'): 1,\n",
              " ('Asilo', '*'): 1,\n",
              " ('[', 'Pre-Estribillo'): 1,\n",
              " ('Pre-Estribillo', ':'): 1,\n",
              " ('So', 'if'): 1,\n",
              " ('if', 'you'): 1,\n",
              " ('want', 'me'): 1,\n",
              " ('me', 'to'): 1,\n",
              " ('to', 'want'): 1,\n",
              " ('what', 'I'): 1,\n",
              " ('I', 'believe'): 1,\n",
              " ('believe', 'that'): 1,\n",
              " ('that', 'I'): 1,\n",
              " ('I', 'want'): 1,\n",
              " ('want', '*'): 1,\n",
              " ('*', 'Can'): 1,\n",
              " ('Can', 'I'): 1,\n",
              " ('I', 'choose'): 1,\n",
              " ('choose', 'to'): 1,\n",
              " ('to', 'quit'): 1,\n",
              " ('quit', '?'): 1,\n",
              " ('Verso', '2'): 1,\n",
              " ('2', ':'): 1,\n",
              " ('*', 'Por'): 1,\n",
              " ('Por', 'ejemplo'): 1,\n",
              " ('ejemplo', ','): 1,\n",
              " (',', 'esta'): 1,\n",
              " ('esta', 'canci√≥n'): 1,\n",
              " ('canci√≥n', '*'): 1,\n",
              " ('*', '¬øQu√©'): 1,\n",
              " ('¬øQu√©', 'algoritmo'): 1,\n",
              " ('algoritmo', 'la'): 1,\n",
              " ('la', 'pari√≥'): 1,\n",
              " ('pari√≥', '?'): 1,\n",
              " ('*', 'Me'): 1,\n",
              " ('Me', 'pregunto'): 1,\n",
              " ('pregunto', 'si'): 1,\n",
              " ('si', 'fui'): 1,\n",
              " ('fui', 'yo'): 1,\n",
              " ('yo', '*'): 1,\n",
              " ('*', '¬øLa'): 1,\n",
              " ('¬øLa', 'elegiste'): 1,\n",
              " ('elegiste', 'o'): 1,\n",
              " ('o', 'te'): 1,\n",
              " ('te', 'eligi√≥'): 1,\n",
              " ('eligi√≥', '?'): 1,\n",
              " ('Verso', '3'): 1,\n",
              " ('3', ':'): 1,\n",
              " ('*', 'Dios'): 1,\n",
              " ('Dios', 'era'): 1,\n",
              " ('era', 'la'): 1,\n",
              " ('la', 'letra'): 1,\n",
              " ('letra', 'chica'): 1,\n",
              " ('chica', 'al'): 1,\n",
              " ('al', 'final'): 1,\n",
              " ('final', 'del'): 1,\n",
              " ('del', 'papel'): 1,\n",
              " ('papel', '*'): 1,\n",
              " ('*', 'Ya'): 1,\n",
              " ('Ya', 'no'): 1,\n",
              " ('no', 'contamos'): 1,\n",
              " ('contamos', 'con'): 1,\n",
              " ('con', '√âl'): 1,\n",
              " ('√âl', '*'): 1,\n",
              " ('*', 'Fin'): 1,\n",
              " ('Fin', 'de'): 1,\n",
              " ('de', 'la'): 1,\n",
              " ('la', 'Luna'): 1,\n",
              " ('Luna', 'de'): 1,\n",
              " ('de', 'miel'): 1,\n",
              " ('miel', '*'): 1,\n",
              " ('el', 'libre'): 1,\n",
              " ('libre', 'albedr√≠o'): 1,\n",
              " ('albedr√≠o', 'es'): 1,\n",
              " ('es', 'un'): 1,\n",
              " ('un', 'cauce'): 1,\n",
              " ('cauce', 'vac√≠o'): 1,\n",
              " ('vac√≠o', '*'): 1,\n",
              " ('*', 'Un'): 1,\n",
              " ('Un', 'barco'): 1,\n",
              " ('barco', 'que'): 1,\n",
              " ('que', 'no'): 1,\n",
              " ('no', 'tiene'): 1,\n",
              " ('tiene', 'r√≠o'): 1,\n",
              " ('r√≠o', '*'): 1,\n",
              " ('*', 'Ni'): 1,\n",
              " ('Ni', 'timonel'): 1,\n",
              " ('timonel', '*'): 1,\n",
              " ('Verso', '4'): 1,\n",
              " ('4', ':'): 1,\n",
              " ('*', 'Todos'): 1,\n",
              " ('Todos', 'aplauden'): 1,\n",
              " ('aplauden', ','): 1,\n",
              " (',', 't√∫'): 1,\n",
              " ('t√∫', 'tambi√©n'): 1,\n",
              " ('tambi√©n', '*'): 1,\n",
              " ('*', 'Pero'): 1,\n",
              " ('Pero', 'no'): 1,\n",
              " ('no', 'queda'): 1,\n",
              " ('queda', 'claro'): 1,\n",
              " ('claro', 'qui√©n'): 1,\n",
              " ('qui√©n', '*'): 1,\n",
              " ('*', 'Tiene'): 1,\n",
              " ('Tiene', 'del'): 1,\n",
              " ('del', 'mango'): 1,\n",
              " ('mango', 'a'): 1,\n",
              " ('a', 'la'): 1,\n",
              " ('la', 'sart√©n'): 1,\n",
              " ('sart√©n', '*'): 1,\n",
              " ('*', 'Del'): 1,\n",
              " ('Del', 'sacrificio'): 1,\n",
              " ('sacrificio', '*'): 1,\n",
              " ('*', 'Piel'): 1,\n",
              " ('Piel', 'o'): 1,\n",
              " ('o', 'silicio'): 1,\n",
              " ('silicio', '*'): 1,\n",
              " ('el', 'precipicio'): 1,\n",
              " ('precipicio', '*'): 1,\n",
              " ('*', 'Dice'): 1,\n",
              " ('Dice', ':'): 1,\n",
              " (':', 'Ven'): 1,\n",
              " ('Ven', ','): 1,\n",
              " ('ven', ','): 1,\n",
              " ('ven', '*'): 1,\n",
              " ('*', '('): 1,\n",
              " ('(', 'Dime'): 1,\n",
              " ('cantar', ')'): 1,\n",
              " (')', '*'): 1}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jCpbhiXp3Gpg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('?', '*', '*'): 18,\n",
              " ('*', '*', '¬øQui√©n'): 11,\n",
              " ('*', '¬øQui√©n', 'quiere'): 11,\n",
              " ('¬øQui√©n', 'quiere', 'que'): 11,\n",
              " ('quiere', 'que', 'yo'): 11,\n",
              " ('que', 'yo', 'quiera'): 11,\n",
              " ('yo', 'quiera', 'lo'): 11,\n",
              " ('quiera', 'lo', 'que'): 11,\n",
              " ('lo', 'que', 'creo'): 11,\n",
              " ('que', 'creo', 'que'): 11,\n",
              " ('creo', 'que', 'quiero'): 11,\n",
              " ('que', 'quiero', '?'): 11,\n",
              " ('quiero', '?', '*'): 11,\n",
              " ('*', '*', '['): 10,\n",
              " (']', '*', '*'): 10,\n",
              " (':', 'Jorge', 'Drexler'): 7,\n",
              " ('Jorge', 'Drexler', ']'): 7,\n",
              " ('Drexler', ']', '*'): 7,\n",
              " ('*', '[', 'Verso'): 4,\n",
              " ('Nora', 'Erez', ']'): 3,\n",
              " ('Erez', ']', '*'): 3,\n",
              " ('Dime', 'qu√©', 'debo'): 3,\n",
              " ('qu√©', 'debo', 'cantar'): 3,\n",
              " ('will', '*', '*'): 3,\n",
              " ('*', '*', 'Jorge'): 3,\n",
              " ('*', 'Jorge', 'Drexler'): 3,\n",
              " ('Jorge', 'Drexler', '*'): 3,\n",
              " ('Drexler', '*', '*'): 3,\n",
              " ('*', '[', 'Refr√°n'): 2,\n",
              " ('[', 'Refr√°n', ':'): 2,\n",
              " ('Refr√°n', ':', 'Jorge'): 2,\n",
              " ('*', '[', 'Estribillo'): 2,\n",
              " ('[', 'Estribillo', ':'): 2,\n",
              " ('Estribillo', ':', 'Jorge'): 2,\n",
              " ('*', '*', 'Dime'): 2,\n",
              " ('*', 'Dime', 'qu√©'): 2,\n",
              " ('debo', 'cantar', '*'): 2,\n",
              " ('cantar', '*', '*'): 2,\n",
              " ('*', '*', 'Oh'): 2,\n",
              " ('*', 'Oh', ','): 2,\n",
              " ('Oh', ',', 'algoritmo'): 2,\n",
              " (',', 'algoritmo', '*'): 2,\n",
              " ('algoritmo', '*', '*'): 2,\n",
              " ('*', '*', 'S√©'): 2,\n",
              " ('*', 'S√©', 'que'): 2,\n",
              " ('S√©', 'que', 'lo'): 2,\n",
              " ('que', 'lo', 'sabes'): 2,\n",
              " ('lo', 'sabes', 'mejor'): 2,\n",
              " ('sabes', 'mejor', '*'): 2,\n",
              " ('mejor', '*', '*'): 2,\n",
              " ('*', '*', 'Incluso'): 2,\n",
              " ('*', 'Incluso', 'que'): 2,\n",
              " ('Incluso', 'que', 'yo'): 2,\n",
              " ('que', 'yo', 'mismo'): 2,\n",
              " ('yo', 'mismo', '*'): 2,\n",
              " ('mismo', '*', '*'): 2,\n",
              " (':', 'Nora', 'Erez'): 2,\n",
              " ('*', '*', 'So'): 2,\n",
              " ('*', '*', 'Conscious'): 2,\n",
              " ('*', 'Conscious', 'is'): 2,\n",
              " ('Conscious', 'is', 'free'): 2,\n",
              " ('is', 'free', ','): 2,\n",
              " ('free', ',', 'but'): 2,\n",
              " (',', 'but', 'not'): 2,\n",
              " ('but', 'not', 'the'): 2,\n",
              " ('not', 'the', 'will'): 2,\n",
              " ('the', 'will', '*'): 2,\n",
              " ('*', '*', 'Y'): 2,\n",
              " ('*', 'Y', 'el'): 2,\n",
              " ('*', '[', 'Letra'): 1,\n",
              " ('[', 'Letra', 'de'): 1,\n",
              " ('Letra', 'de', '``'): 1,\n",
              " ('de', '``', '¬°Oh'): 1,\n",
              " ('``', '¬°Oh', ','): 1,\n",
              " ('¬°Oh', ',', 'Algoritmo'): 1,\n",
              " (',', 'Algoritmo', '!'): 1,\n",
              " ('Algoritmo', '!', \"''\"): 1,\n",
              " ('!', \"''\", 'ft.'): 1,\n",
              " (\"''\", 'ft.', 'Nora'): 1,\n",
              " ('ft.', 'Nora', 'Erez'): 1,\n",
              " ('[', 'Verso', '1'): 1,\n",
              " ('Verso', '1', ':'): 1,\n",
              " ('1', ':', 'Nora'): 1,\n",
              " ('*', '*', 'Wait'): 1,\n",
              " ('*', 'Wait', ','): 1,\n",
              " ('Wait', ',', 'what'): 1,\n",
              " (',', 'what', \"'s\"): 1,\n",
              " ('what', \"'s\", 'that'): 1,\n",
              " (\"'s\", 'that', 'money'): 1,\n",
              " ('that', 'money', 'that'): 1,\n",
              " ('money', 'that', 'you'): 1,\n",
              " ('that', 'you', 'spent'): 1,\n",
              " ('you', 'spent', '?'): 1,\n",
              " ('spent', '?', '*'): 1,\n",
              " ('*', '*', 'What'): 1,\n",
              " ('*', 'What', \"'s\"): 1,\n",
              " ('What', \"'s\", 'that'): 1,\n",
              " (\"'s\", 'that', 'sitting'): 1,\n",
              " ('that', 'sitting', 'on'): 1,\n",
              " ('sitting', 'on', 'your'): 1,\n",
              " ('on', 'your', 'plate'): 1,\n",
              " ('your', 'plate', '?'): 1,\n",
              " ('plate', '?', '*'): 1,\n",
              " ('*', '*', 'Do'): 1,\n",
              " ('*', 'Do', 'you'): 1,\n",
              " ('Do', 'you', 'want'): 1,\n",
              " ('you', 'want', 'what'): 1,\n",
              " ('want', 'what', 'you'): 1,\n",
              " ('what', 'you', \"'ve\"): 1,\n",
              " ('you', \"'ve\", 'been'): 1,\n",
              " (\"'ve\", 'been', 'fed'): 1,\n",
              " ('been', 'fed', '?'): 1,\n",
              " ('fed', '?', '*'): 1,\n",
              " ('*', '*', 'Are'): 1,\n",
              " ('*', 'Are', 'you'): 1,\n",
              " ('Are', 'you', 'the'): 1,\n",
              " ('you', 'the', 'fish'): 1,\n",
              " ('the', 'fish', 'or'): 1,\n",
              " ('fish', 'or', 'bait'): 1,\n",
              " ('or', 'bait', '?'): 1,\n",
              " ('bait', '?', '*'): 1,\n",
              " ('*', '*', 'Mmm'): 1,\n",
              " ('*', 'Mmm', ','): 1,\n",
              " ('Mmm', ',', 'I'): 1,\n",
              " (',', 'I', \"'m\"): 1,\n",
              " ('I', \"'m\", 'on'): 1,\n",
              " (\"'m\", 'on', 'the'): 1,\n",
              " ('on', 'the', 'top'): 1,\n",
              " ('the', 'top', 'of'): 1,\n",
              " ('top', 'of', 'the'): 1,\n",
              " ('of', 'the', 'roof'): 1,\n",
              " ('the', 'roof', 'and'): 1,\n",
              " ('roof', 'and', 'I'): 1,\n",
              " ('and', 'I', 'feel'): 1,\n",
              " ('I', 'feel', 'like'): 1,\n",
              " ('feel', 'like', 'a'): 1,\n",
              " ('like', 'a', 'jail'): 1,\n",
              " ('a', 'jail', '*'): 1,\n",
              " ('jail', '*', '*'): 1,\n",
              " ('*', '*', 'Rather'): 1,\n",
              " ('*', 'Rather', 'not'): 1,\n",
              " ('Rather', 'not', 'pay'): 1,\n",
              " ('not', 'pay', 'the'): 1,\n",
              " ('pay', 'the', 'bail'): 1,\n",
              " ('the', 'bail', '*'): 1,\n",
              " ('bail', '*', '*'): 1,\n",
              " ('*', '*', 'To'): 1,\n",
              " ('*', 'To', 'dangerous'): 1,\n",
              " ('To', 'dangerous', 'people'): 1,\n",
              " ('dangerous', 'people', 'with'): 1,\n",
              " ('people', 'with', 'blood'): 1,\n",
              " ('with', 'blood', 'on'): 1,\n",
              " ('blood', 'on', 'their'): 1,\n",
              " ('on', 'their', 'faces'): 1,\n",
              " ('their', 'faces', '*'): 1,\n",
              " ('faces', '*', '*'): 1,\n",
              " ('*', 'So', 'I'): 1,\n",
              " ('So', 'I', \"'m\"): 1,\n",
              " ('I', \"'m\", 'sharing'): 1,\n",
              " (\"'m\", 'sharing', 'a'): 1,\n",
              " ('sharing', 'a', 'cell'): 1,\n",
              " ('a', 'cell', 'with'): 1,\n",
              " ('cell', 'with', 'the'): 1,\n",
              " ('with', 'the', 'masses'): 1,\n",
              " ('the', 'masses', '*'): 1,\n",
              " ('masses', '*', '*'): 1,\n",
              " ('*', '*', 'The'): 1,\n",
              " ('*', 'The', 'underground'): 1,\n",
              " ('The', 'underground', 'always'): 1,\n",
              " ('underground', 'always', 'strive'): 1,\n",
              " ('always', 'strive', 'for'): 1,\n",
              " ('strive', 'for', 'the'): 1,\n",
              " ('for', 'the', 'main'): 1,\n",
              " ('the', 'main', '*'): 1,\n",
              " ('main', '*', '*'): 1,\n",
              " ('*', '*', 'Streaming'): 1,\n",
              " ('*', 'Streaming', 'like'): 1,\n",
              " ('Streaming', 'like', 'Grande'): 1,\n",
              " ('like', 'Grande', \"'s\"): 1,\n",
              " ('Grande', \"'s\", 'big-ass'): 1,\n",
              " (\"'s\", 'big-ass', 'ring'): 1,\n",
              " ('big-ass', 'ring', '*'): 1,\n",
              " ('ring', '*', '*'): 1,\n",
              " ('*', '*', 'Screaming'): 1,\n",
              " ('*', 'Screaming', ':'): 1,\n",
              " ('Screaming', ':', 'I'): 1,\n",
              " (':', 'I', \"'ll\"): 1,\n",
              " ('I', \"'ll\", 'write'): 1,\n",
              " (\"'ll\", 'write', 'you'): 1,\n",
              " ('write', 'you', 'out'): 1,\n",
              " ('you', 'out', 'my'): 1,\n",
              " ('out', 'my', 'will'): 1,\n",
              " ('my', 'will', '*'): 1,\n",
              " ('*', '*', 'You'): 1,\n",
              " ('*', 'You', 'might'): 1,\n",
              " ('You', 'might', 'also'): 1,\n",
              " ('might', 'also', 'like'): 1,\n",
              " ('also', 'like', '*'): 1,\n",
              " ('like', '*', '*'): 1,\n",
              " ('*', '*', 'Amor'): 1,\n",
              " ('*', 'Amor', 'al'): 1,\n",
              " ('Amor', 'al', 'Arte'): 1,\n",
              " ('al', 'Arte', '*'): 1,\n",
              " ('Arte', '*', '*'): 1,\n",
              " ('*', '*', 'Tinta'): 1,\n",
              " ('*', 'Tinta', 'y'): 1,\n",
              " ('Tinta', 'y', 'Tiempo'): 1,\n",
              " ('y', 'Tiempo', '*'): 1,\n",
              " ('Tiempo', '*', '*'): 1,\n",
              " ('*', '*', 'Asilo'): 1,\n",
              " ('*', 'Asilo', '*'): 1,\n",
              " ('Asilo', '*', '*'): 1,\n",
              " ('*', '[', 'Pre-Estribillo'): 1,\n",
              " ('[', 'Pre-Estribillo', ':'): 1,\n",
              " ('Pre-Estribillo', ':', 'Nora'): 1,\n",
              " ('*', 'So', 'if'): 1,\n",
              " ('So', 'if', 'you'): 1,\n",
              " ('if', 'you', 'want'): 1,\n",
              " ('you', 'want', 'me'): 1,\n",
              " ('want', 'me', 'to'): 1,\n",
              " ('me', 'to', 'want'): 1,\n",
              " ('to', 'want', 'what'): 1,\n",
              " ('want', 'what', 'I'): 1,\n",
              " ('what', 'I', 'believe'): 1,\n",
              " ('I', 'believe', 'that'): 1,\n",
              " ('believe', 'that', 'I'): 1,\n",
              " ('that', 'I', 'want'): 1,\n",
              " ('I', 'want', '*'): 1,\n",
              " ('want', '*', '*'): 1,\n",
              " ('*', '*', 'Can'): 1,\n",
              " ('*', 'Can', 'I'): 1,\n",
              " ('Can', 'I', 'choose'): 1,\n",
              " ('I', 'choose', 'to'): 1,\n",
              " ('choose', 'to', 'quit'): 1,\n",
              " ('to', 'quit', '?'): 1,\n",
              " ('quit', '?', '*'): 1,\n",
              " ('[', 'Verso', '2'): 1,\n",
              " ('Verso', '2', ':'): 1,\n",
              " ('2', ':', 'Jorge'): 1,\n",
              " ('*', '*', 'Por'): 1,\n",
              " ('*', 'Por', 'ejemplo'): 1,\n",
              " ('Por', 'ejemplo', ','): 1,\n",
              " ('ejemplo', ',', 'esta'): 1,\n",
              " (',', 'esta', 'canci√≥n'): 1,\n",
              " ('esta', 'canci√≥n', '*'): 1,\n",
              " ('canci√≥n', '*', '*'): 1,\n",
              " ('*', '*', '¬øQu√©'): 1,\n",
              " ('*', '¬øQu√©', 'algoritmo'): 1,\n",
              " ('¬øQu√©', 'algoritmo', 'la'): 1,\n",
              " ('algoritmo', 'la', 'pari√≥'): 1,\n",
              " ('la', 'pari√≥', '?'): 1,\n",
              " ('pari√≥', '?', '*'): 1,\n",
              " ('*', '*', 'Me'): 1,\n",
              " ('*', 'Me', 'pregunto'): 1,\n",
              " ('Me', 'pregunto', 'si'): 1,\n",
              " ('pregunto', 'si', 'fui'): 1,\n",
              " ('si', 'fui', 'yo'): 1,\n",
              " ('fui', 'yo', '*'): 1,\n",
              " ('yo', '*', '*'): 1,\n",
              " ('*', '*', '¬øLa'): 1,\n",
              " ('*', '¬øLa', 'elegiste'): 1,\n",
              " ('¬øLa', 'elegiste', 'o'): 1,\n",
              " ('elegiste', 'o', 'te'): 1,\n",
              " ('o', 'te', 'eligi√≥'): 1,\n",
              " ('te', 'eligi√≥', '?'): 1,\n",
              " ('eligi√≥', '?', '*'): 1,\n",
              " ('[', 'Verso', '3'): 1,\n",
              " ('Verso', '3', ':'): 1,\n",
              " ('3', ':', 'Jorge'): 1,\n",
              " ('*', '*', 'Dios'): 1,\n",
              " ('*', 'Dios', 'era'): 1,\n",
              " ('Dios', 'era', 'la'): 1,\n",
              " ('era', 'la', 'letra'): 1,\n",
              " ('la', 'letra', 'chica'): 1,\n",
              " ('letra', 'chica', 'al'): 1,\n",
              " ('chica', 'al', 'final'): 1,\n",
              " ('al', 'final', 'del'): 1,\n",
              " ('final', 'del', 'papel'): 1,\n",
              " ('del', 'papel', '*'): 1,\n",
              " ('papel', '*', '*'): 1,\n",
              " ('*', '*', 'Ya'): 1,\n",
              " ('*', 'Ya', 'no'): 1,\n",
              " ('Ya', 'no', 'contamos'): 1,\n",
              " ('no', 'contamos', 'con'): 1,\n",
              " ('contamos', 'con', '√âl'): 1,\n",
              " ('con', '√âl', '*'): 1,\n",
              " ('√âl', '*', '*'): 1,\n",
              " ('*', '*', 'Fin'): 1,\n",
              " ('*', 'Fin', 'de'): 1,\n",
              " ('Fin', 'de', 'la'): 1,\n",
              " ('de', 'la', 'Luna'): 1,\n",
              " ('la', 'Luna', 'de'): 1,\n",
              " ('Luna', 'de', 'miel'): 1,\n",
              " ('de', 'miel', '*'): 1,\n",
              " ('miel', '*', '*'): 1,\n",
              " ('Y', 'el', 'libre'): 1,\n",
              " ('el', 'libre', 'albedr√≠o'): 1,\n",
              " ('libre', 'albedr√≠o', 'es'): 1,\n",
              " ('albedr√≠o', 'es', 'un'): 1,\n",
              " ('es', 'un', 'cauce'): 1,\n",
              " ('un', 'cauce', 'vac√≠o'): 1,\n",
              " ('cauce', 'vac√≠o', '*'): 1,\n",
              " ('vac√≠o', '*', '*'): 1,\n",
              " ('*', '*', 'Un'): 1,\n",
              " ('*', 'Un', 'barco'): 1,\n",
              " ('Un', 'barco', 'que'): 1,\n",
              " ('barco', 'que', 'no'): 1,\n",
              " ('que', 'no', 'tiene'): 1,\n",
              " ('no', 'tiene', 'r√≠o'): 1,\n",
              " ('tiene', 'r√≠o', '*'): 1,\n",
              " ('r√≠o', '*', '*'): 1,\n",
              " ('*', '*', 'Ni'): 1,\n",
              " ('*', 'Ni', 'timonel'): 1,\n",
              " ('Ni', 'timonel', '*'): 1,\n",
              " ('timonel', '*', '*'): 1,\n",
              " ('[', 'Verso', '4'): 1,\n",
              " ('Verso', '4', ':'): 1,\n",
              " ('4', ':', 'Jorge'): 1,\n",
              " ('*', '*', 'Todos'): 1,\n",
              " ('*', 'Todos', 'aplauden'): 1,\n",
              " ('Todos', 'aplauden', ','): 1,\n",
              " ('aplauden', ',', 't√∫'): 1,\n",
              " (',', 't√∫', 'tambi√©n'): 1,\n",
              " ('t√∫', 'tambi√©n', '*'): 1,\n",
              " ('tambi√©n', '*', '*'): 1,\n",
              " ('*', '*', 'Pero'): 1,\n",
              " ('*', 'Pero', 'no'): 1,\n",
              " ('Pero', 'no', 'queda'): 1,\n",
              " ('no', 'queda', 'claro'): 1,\n",
              " ('queda', 'claro', 'qui√©n'): 1,\n",
              " ('claro', 'qui√©n', '*'): 1,\n",
              " ('qui√©n', '*', '*'): 1,\n",
              " ('*', '*', 'Tiene'): 1,\n",
              " ('*', 'Tiene', 'del'): 1,\n",
              " ('Tiene', 'del', 'mango'): 1,\n",
              " ('del', 'mango', 'a'): 1,\n",
              " ('mango', 'a', 'la'): 1,\n",
              " ('a', 'la', 'sart√©n'): 1,\n",
              " ('la', 'sart√©n', '*'): 1,\n",
              " ('sart√©n', '*', '*'): 1,\n",
              " ('*', '*', 'Del'): 1,\n",
              " ('*', 'Del', 'sacrificio'): 1,\n",
              " ('Del', 'sacrificio', '*'): 1,\n",
              " ('sacrificio', '*', '*'): 1,\n",
              " ('*', '*', 'Piel'): 1,\n",
              " ('*', 'Piel', 'o'): 1,\n",
              " ('Piel', 'o', 'silicio'): 1,\n",
              " ('o', 'silicio', '*'): 1,\n",
              " ('silicio', '*', '*'): 1,\n",
              " ('Y', 'el', 'precipicio'): 1,\n",
              " ('el', 'precipicio', '*'): 1,\n",
              " ('precipicio', '*', '*'): 1,\n",
              " ('*', '*', 'Dice'): 1,\n",
              " ('*', 'Dice', ':'): 1,\n",
              " ('Dice', ':', 'Ven'): 1,\n",
              " (':', 'Ven', ','): 1,\n",
              " ('Ven', ',', 'ven'): 1,\n",
              " (',', 'ven', ','): 1,\n",
              " ('ven', ',', 'ven'): 1,\n",
              " (',', 'ven', '*'): 1,\n",
              " ('ven', '*', '*'): 1,\n",
              " ('*', '*', '('): 1,\n",
              " ('*', '(', 'Dime'): 1,\n",
              " ('(', 'Dime', 'qu√©'): 1,\n",
              " ('debo', 'cantar', ')'): 1,\n",
              " ('cantar', ')', '*'): 1,\n",
              " (')', '*', '*'): 1}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgEpVPj21fs"
      },
      "source": [
        "Debe mostrar que su m√©todo funciona para $N = 1,2,3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzLfBLBk-i7"
      },
      "source": [
        "## P7. Perplexity (1 punto)\n",
        "\n",
        "En esta secci√≥n evaluar√°n su modelo de n-gramas y determinar√°n la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\text{Perplexity} = 2^{-l} \\quad \\quad l = \\frac{1}{M} \\sum_{i=1}^{m} \\log p(s_i)\n",
        "$$\n",
        "\n",
        "con $m$ el n√∫mero de oraciones del corpus y $M$ el tama√±o del vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tas4KYhZ28_C"
      },
      "source": [
        "### 7.a Obtener probabilidades (0.5 puntos)\n",
        "\n",
        "En esta secci√≥n implementar√° una funci√≥n que determine la probabilidad de una oraci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYH0ScM44Jrb"
      },
      "source": [
        "Defina una funci√≥n que reciba una oraci√≥n, un diccionario con n-gramas y el valor de $n$. La funci√≥n debe entregar la probabilidad de cualquier oraci√≥n.\n",
        "\n",
        "**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "aWGsq22H4Sxz"
      },
      "outputs": [],
      "source": [
        "def get_probability(sentence, n_grams_frequency, n):\n",
        "    tokens = ['*'] * (n-1) + word_tokenize(sentence) + ['*'] * (n-1) \n",
        "    #print(tokens)\n",
        "    V = len(set([token for n_gram in n_grams_frequency.keys() for token in n_gram])) + 1  # +1 for OOV (Out of Vocabulary) token\n",
        "    probability_log_sum = 0\n",
        "    for i in range(n-1, len(tokens)):\n",
        "        n_gram = tuple(tokens[i-n+1:i+1])\n",
        "        prefix = tuple(tokens[i-n+1:i])\n",
        "        \n",
        "        # Calculate counts\n",
        "        n_gram_count = n_grams_frequency.get(n_gram, 0)\n",
        "        prefix_count = sum([count for key, count in n_grams_frequency.items() if key[:n-1] == prefix])\n",
        "        \n",
        "        # Apply Laplace smoothing\n",
        "        probability = (n_gram_count + 1) / (prefix_count + V)\n",
        "        probability_log_sum += math.log(probability)\n",
        "    \n",
        "    return math.exp(probability_log_sum)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1UkfOz75W_P"
      },
      "source": [
        "Pruebe su funci√≥n con oraciones frecuentes y comente sus resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7ITfzYJx5fqV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Probabilidades para N = 1:\n",
            "Oraci√≥n: '(Oh, algoritmo)'\n",
            "Probabilidad: 4.599417207845598e-12\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 5.689703773464625e-18\n",
            "\n",
            "Oraci√≥n: '(S√© que lo sabes mejor)'\n",
            "Probabilidad: 1.080958073124866e-15\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 5.689703773464625e-18\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 5.689703773464625e-18\n",
            "\n",
            "\n",
            "Probabilidades para N = 2:\n",
            "Oraci√≥n: '(Oh, algoritmo)'\n",
            "Probabilidad: 4.170077022376801e-13\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 1.2863287869802262e-15\n",
            "\n",
            "Oraci√≥n: '(S√© que lo sabes mejor)'\n",
            "Probabilidad: 7.988893043866766e-17\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 1.2863287869802262e-15\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 1.2863287869802262e-15\n",
            "\n",
            "\n",
            "Probabilidades para N = 3:\n",
            "Oraci√≥n: '(Oh, algoritmo)'\n",
            "Probabilidad: 7.487392908217185e-16\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 9.305844958294771e-17\n",
            "\n",
            "Oraci√≥n: '(S√© que lo sabes mejor)'\n",
            "Probabilidad: 1.701637235775728e-19\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 9.305844958294771e-17\n",
            "\n",
            "Oraci√≥n: '¬øQui√©n quiere que yo quiera lo que creo que quiero?'\n",
            "Probabilidad: 9.305844958294771e-17\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calcula los n-gramas para N = 1, 2, 3 usando el corpus de entrenamiento\n",
        "n_grams_1 = n_grams(train_corpus, n=1)\n",
        "n_grams_2 = n_grams(train_corpus, n=2)\n",
        "n_grams_3 = n_grams(train_corpus, n=3)\n",
        "\n",
        "# Selecciona algunas oraciones del conjunto de prueba para evaluar\n",
        "test_sentences = test_corpus[:5]  # Se toman las primeras 5\n",
        "\n",
        "# Funci√≥n para imprimir las probabilidades de un conjunto de oraciones para un determinado N\n",
        "def print_sentence_probabilities(sentences, n_grams_frequency, n):\n",
        "    print(f\"\\nProbabilidades para N = {n}:\")\n",
        "    for sentence in sentences:\n",
        "        probability = get_probability(sentence, n_grams_frequency, n)\n",
        "        print(f\"Oraci√≥n: '{sentence}'\\nProbabilidad: {probability}\\n\")\n",
        "\n",
        "# Imprime las probabilidades para N = 1, 2, 3\n",
        "print_sentence_probabilities(test_sentences, n_grams_1, 1)\n",
        "print_sentence_probabilities(test_sentences, n_grams_2, 2)\n",
        "print_sentence_probabilities(test_sentences, n_grams_3, 3)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el corpus: ['algoritmo']\n",
            "Palabras OOV: ['crep√∫sculo', 'dinosaurio', 'galaxia', 'datos']\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de palabras al azar para verificar\n",
        "palabras_al_azar = [\"crep√∫sculo\", \"dinosaurio\", \"galaxia\", \"algoritmo\", \"datos\"]\n",
        "\n",
        "# Asumiendo que ya has generado n_grams_1 del train_corpus y extra√≠do el vocabulario\n",
        "vocabulario_train_corpus = set(word for (word,) in n_grams_1.keys())\n",
        "\n",
        "# Clasificar palabras al azar en presentes en el corpus o OOV\n",
        "palabras_en_corpus = []\n",
        "palabras_oov = []\n",
        "\n",
        "for palabra in palabras_al_azar:\n",
        "    if palabra in vocabulario_train_corpus:\n",
        "        palabras_en_corpus.append(palabra)\n",
        "    else:\n",
        "        palabras_oov.append(palabra)\n",
        "\n",
        "print(\"Palabras en el corpus:\", palabras_en_corpus)\n",
        "print(\"Palabras OOV:\", palabras_oov)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Genera oraciones de prueba\n",
        "def generar_oraciones_test(palabras_oov, palabras_en_vocabulario):\n",
        "    oraciones = {\n",
        "        \"completamente_oov\": \" \".join(palabras_oov) + \".\",\n",
        "        \"mixta\": \" \".join(palabras_en_vocabulario + [palabras_oov[0]]) + \".\",\n",
        "        \"una_palabra_oov\": \"El \" + palabras_oov[1] + \" es desconocido.\"\n",
        "    }\n",
        "    return oraciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completamente_oov: crep√∫sculo dinosaurio galaxia datos.\n",
            "Mixta: algoritmo crep√∫sculo.\n",
            "Una_palabra_oov: El dinosaurio es desconocido.\n"
          ]
        }
      ],
      "source": [
        "# Llama a la funci√≥n y guarda el resultado\n",
        "oraciones_de_prueba = generar_oraciones_test(palabras_oov, palabras_en_corpus)\n",
        "\n",
        "# Imprime las oraciones de prueba generadas\n",
        "for tipo, oracion in oraciones_de_prueba.items():\n",
        "    print(f\"{tipo.capitalize()}: {oracion}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Probabilidades para n=1:\n",
            "Completamente_oov: 'crep√∫sculo dinosaurio galaxia datos.' - Probabilidad: 7.985099319176363e-15\n",
            "Mixta: 'algoritmo crep√∫sculo.' - Probabilidad: 1.3913237053732918e-08\n",
            "Una_palabra_oov: 'El dinosaurio es desconocido.' - Probabilidad: 1.5970198638352814e-14\n",
            "\n",
            "Probabilidades para n=2:\n",
            "Completamente_oov: 'crep√∫sculo dinosaurio galaxia datos.' - Probabilidad: 1.2670309761289526e-14\n",
            "Mixta: 'algoritmo crep√∫sculo.' - Probabilidad: 4.843462207529971e-10\n",
            "Una_palabra_oov: 'El dinosaurio es desconocido.' - Probabilidad: 1.2606318297848626e-14\n",
            "\n",
            "Probabilidades para n=3:\n",
            "Completamente_oov: 'crep√∫sculo dinosaurio galaxia datos.' - Probabilidad: 6.431629320451519e-17\n",
            "Mixta: 'algoritmo crep√∫sculo.' - Probabilidad: 2.4960510229740346e-12\n",
            "Una_palabra_oov: 'El dinosaurio es desconocido.' - Probabilidad: 6.431629320451519e-17\n"
          ]
        }
      ],
      "source": [
        "# Calcular la probabilidad para cada oraci√≥n de prueba y para cada n\n",
        "resultados_probabilidades = {}\n",
        "for n, n_grams_freq in zip([1, 2, 3], [n_grams_1, n_grams_2, n_grams_3]):\n",
        "    print(f\"\\nProbabilidades para n={n}:\")\n",
        "    for tipo, oracion in oraciones_de_prueba.items():\n",
        "        probabilidad = get_probability(oracion, n_grams_freq, n)\n",
        "        print(f\"{tipo.capitalize()}: '{oracion}' - Probabilidad: {probabilidad}\")\n",
        "        resultados_probabilidades[f\"{tipo}_{n}\"] = probabilidad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnIFV7F3eOL"
      },
      "source": [
        "### 7.b Perplexity en conjunto de test (0.5 puntos)\n",
        "\n",
        "En esta sub-secci√≥n deber√° calcular la perplejidad del corpus de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N21I_mPl5Cqx"
      },
      "source": [
        "Defina una funci√≥n que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_perplexity(corpus, n):\n",
        "    n_grams_frequency = n_grams(train_corpus, n)\n",
        "    \n",
        "    # Aqu√≠, corpus es el corpus de test.\n",
        "    # Calcular la probabilidad logar√≠tmica total de todas las oraciones en el corpus de test\n",
        "    total_log_probability = 0\n",
        "    M = 0  # Total number of tokens\n",
        "    \n",
        "    for sentence in corpus:\n",
        "        # Calcular la probabilidad de la oraci√≥n actual y sumar su logaritmo al total\n",
        "        sentence_probability = get_probability(sentence, n_grams_frequency, n)\n",
        "        total_log_probability += math.log(sentence_probability)\n",
        "        \n",
        "        # Actualizar el contador total de tokens\n",
        "        M += len(word_tokenize(sentence)) + ((n - 1)*2)  # +n-1 por los tokens de inicio/final a√±adidos\n",
        "    \n",
        "    # Calcular el promedio de la probabilidad logar√≠tmica por token\n",
        "    l = total_log_probability / M\n",
        "    \n",
        "    # Calcular y devolver la perplejidad\n",
        "    perplexity = math.pow(2, -l)\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OAjpRDoG5sUJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.605013477568717"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_perplexity(test_corpus, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhc07wXM5gyI"
      },
      "source": [
        "D√© una interpretacion de la perplexity en el corpus de test:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dada una perplexity aproximada de 7.6 para el modelo de trigramas en el corpus de test, compuesto exclusivamente por el texto de la canci√≥n \"Oh algoritmo\", esta medida indica que el modelo, en promedio, selecciona entre aproximadamente ocho posibles palabras siguientes en el texto de manera precisa. La perplejidad, al ser una medida de cu√°n bien un modelo de probabilidad predice una muestra, sugiere que el modelo tiene un buen desempe√±o en este contexto espec√≠fico.\n",
        "\n",
        "Este nivel de perplexity podr√≠a interpretarse como que el modelo de trigramas logra un equilibrio efectivo entre generalizaci√≥n y precisi√≥n para este corpus limitado. Es capaz de predecir con relativa precisi√≥n las palabras siguientes en el texto, lo que indica una afinidad y ajuste cercano al estilo y vocabulario espec√≠ficos de la canci√≥n. Sin embargo, es importante considerar que dado el tama√±o relativamente peque√±o y la naturaleza espec√≠fica del corpus (una √∫nica canci√≥n), el modelo puede no generalizar bien a otros textos o contextos ling√º√≠sticos fuera de este dominio espec√≠fico.\n",
        "\n",
        "Adem√°s, el proceso de suavizado de Laplace aplicado en el c√°lculo de probabilidades ayud√≥ a manejar casos de palabras fuera del vocabulario, lo cual es crucial para modelos basados en corpus de tama√±o limitado y evita la asignaci√≥n de probabilidades cero a secuencias no vistas durante el entrenamiento. La aplicaci√≥n de este suavizado permiti√≥ al modelo manejar mejor la incertidumbre y contribuy√≥ a la perplejidad relativamente baja observada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNsmR4OPQQX"
      },
      "source": [
        "## P8. Interpolaci√≥n Lineal (0.5 puntos)\n",
        "\n",
        "Cree una funci√≥n que obtenga la probabilidad de una oraci√≥n interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\\lambda_1, \\lambda_2$ y $\\lambda_3$ respectivamente. Para esto use las funciones que cre√≥ anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):\n",
        "    # Asegurar que la suma de lambdas sea 1\n",
        "    assert l_1 + l_2 + l_3 == 1, \"La suma de lambdas debe ser 1\"\n",
        "    # Calcular n-gramas para n=1, 2, 3 usando todo el corpus para tener una base de datos completa de frecuencias?? o usar solo el train?\n",
        "    n_grams_1 = n_grams(corpus, 1)\n",
        "    n_grams_2 = n_grams(corpus, 2)\n",
        "    n_grams_3 = n_grams(corpus, 3)\n",
        "    \n",
        "    # Calcular la probabilidad interpolada de la oraci√≥n\n",
        "    sentence_probability = 1\n",
        "\n",
        "    p1 = get_probability(sentence, n_grams_1, 1)\n",
        "    p2 = get_probability(sentence, n_grams_2, 2)\n",
        "    p3 = get_probability(sentence, n_grams_3, 3)\n",
        "\n",
        "    # Interpolaci√≥n lineal de las probabilidades\n",
        "    p = l_1 * p1 + l_2 * p2 + l_3 * p3\n",
        "    sentence_probability *= p\n",
        "    \n",
        "    return sentence_probability, len(word_tokenize(sentence)) + ((n - 1)*2) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1J_E77RQp3"
      },
      "source": [
        "Defina una funci√≥n para calcular la perplejidad de un corpus con interpolaci√≥n lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "oAS94E1UROkg"
      },
      "outputs": [],
      "source": [
        "def get_pp_interpol(corpus, l_1, l_2, l_3):\n",
        "\n",
        "    # Inicializar variables para calcular la perplejidad\n",
        "    total_log_probability = 0\n",
        "    M = 0  # Contador total de tokens\n",
        "\n",
        "    for sentence in corpus:\n",
        "\n",
        "        sentence_probability, len_tokens = get_probability_lineal_interpol(sentence, train_corpus, l_1, l_2, l_3)\n",
        "        M += len_tokens   # Ajustar M para no contar los tokens de inicio y fin\n",
        "        total_log_probability += math.log(sentence_probability)\n",
        "\n",
        "    # Calcular la perplejidad\n",
        "    l = total_log_probability / M\n",
        "    perplexity = math.pow(2, -l)\n",
        "    return perplexity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoX9_o2SHOY"
      },
      "source": [
        "Ahora haga pruebas con distintos valores de $\\lambda_1, \\lambda_2$ y $\\lambda_3$, incluyendo valores extremos (por ejemplo $[1, 0, 0]$). Comente sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OZ6-NA3AOUmq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplejidad con Œª1=1, Œª2=0, Œª3=0: 6.769822421660892\n",
            "Perplejidad con Œª1=0, Œª2=1, Œª3=0: 6.0068976018908256\n",
            "Perplejidad con Œª1=0, Œª2=0, Œª3=1: 7.605013477568717\n",
            "Perplejidad con Œª1=0.33, Œª2=0.33, Œª3=0.34: 6.038580577433671\n",
            "Perplejidad con Œª1=0.2, Œª2=0.3, Œª3=0.5: 6.111052853778965\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Diferentes configuraciones de pesos para probar\n",
        "configuraciones_lambda = [\n",
        "    (1, 0, 0),  # Todos los pesos en unigramas\n",
        "    (0, 1, 0),  # Todos los pesos en bigramas\n",
        "    (0, 0, 1),  # Todos los pesos en trigramas\n",
        "    (0.33, 0.33, 0.34),  # Distribuci√≥n equitativa\n",
        "    (0.2, 0.3, 0.5),  # Mayor peso en trigramas\n",
        "    # Agrega m√°s configuraciones seg√∫n lo desees\n",
        "]\n",
        "\n",
        "# Bucle para ejecutar la prueba con cada configuraci√≥n de pesos\n",
        "for l_1, l_2, l_3 in configuraciones_lambda:\n",
        "    pp = get_pp_interpol(test_corpus, l_1, l_2, l_3)\n",
        "    print(f\"Perplejidad con Œª1={l_1}, Œª2={l_2}, Œª3={l_3}: {pp}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La evaluaci√≥n detallada de la perplejidad en funci√≥n de la ponderaci√≥n asignada a los unigramas, bigramas y trigramas en el modelo de n-gramas revela insights significativos sobre el desempe√±o predictivo del modelo utilizando diferentes configuraciones de interpolaci√≥n en el corpus espec√≠fico compuesto por la letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez. Este an√°lisis muestra una jerarqu√≠a clara en la eficacia predictiva de las distintas estructuras de n-gramas, que es esencial para entender c√≥mo la contextualizaci√≥n a diferentes niveles afecta la capacidad del modelo para anticipar el texto.\n",
        "\n",
        "Sorprendentemente, los bigramas (con lambda_2=1) resultaron ser los m√°s efectivos para predecir el conjunto de prueba, logrando la menor perplejidad con un valor de 6.0 aprox. Este resultado subraya el poder de incorporar un nivel de contexto inmediato al predecir la siguiente palabra en una secuencia, proporcionando un equilibrio √≥ptimo entre la especificidad del contexto y la generalidad requerida para una buena capacidad de generalizaci√≥n en este corpus particular.\n",
        "\n",
        "Le siguen las combinaciones de unigramas, bigramas y trigramas con pesos distribuidos (lambda_1=0.33, lambda_2=0.33, lambda_3=0.34 y lambda_1=0.2, lambda_2=0.3, lambda_3=0.5), que tambi√©n muestran una mejora notable en la perplejidad comparado con los modelos que solo consideran un tipo de n-grama. Esto ilustra c√≥mo una estrategia de interpolaci√≥n que integra m√∫ltiples granularidades de contexto puede ser beneficiosa, aprovechando la informaci√≥n proporcionada por la relaci√≥n entre palabras consecutivas y por configuraciones m√°s locales y m√°s amplias dentro de la oraci√≥n.\n",
        "\n",
        "Los unigramas, a pesar de ser el m√©todo m√°s simple al considerar solo la frecuencia de aparici√≥n de palabras individuales sin contexto, sorprendentemente superan a los trigramas con una perplejidad de 6.8 aprox. Esto podr√≠a sugerir que, en un corpus con limitaciones de tama√±o o con una diversidad significativa de construcciones ling√º√≠sticas, la inclusi√≥n de m√°s contexto no siempre conduce a mejoras en la capacidad predictiva, posiblemente debido a la sobre-especificidad y a la dispersi√≥n de los datos en el caso de los trigramas.\n",
        "\n",
        "Finalmente, el modelo basado exclusivamente en trigramas mostr√≥ la mayor perplejidad con un valor de 7.6, indicando que, para este conjunto de datos, considerar tres palabras anteriores en la predicci√≥n puede no ser tan efectivo como las otras configuraciones. Esto podr√≠a reflejar una limitaci√≥n en la disponibilidad de patrones trigramas consistentes dentro del corpus de entrenamiento, lo que resalta los desaf√≠os de equilibrar la riqueza contextual y la disponibilidad de datos suficientes para entrenar modelos predictivos efectivos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
