dado todo esto dame la parte que dice 
Pruebe su función con oraciones frecuentes y comente sus resultados

## P6 N-gramas (0.75 punto)

En esta sección debera determinar los n-gramas del la cancion "Oh algoritmo".

### 6.a Corpus de entrenamiento y test (0.25 puntos)

En esta subsección debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto.

try:
    # Abre el archivo en modo lectura ("r")
    with open("oh_algoritmo.txt", "r") as archivo:
        # Lee el contenido del archivo
        texto = archivo.read()
        # Imprime el contenido
        print(texto)
except FileNotFoundError:
    print("El archivo no se encuentra.")
except Exception as e:
    print("Ocurrió un error:", e)

[Letra de "¡Oh, Algoritmo!" ft. Nora Erez]

[Refrán: Jorge Drexler]
¿Quién quiere que yo quiera lo que creo que quiero?
¿Quién quiere que yo quiera lo que creo que quiero?
...
¿Quién quiere que yo quiera lo que creo que quiero?
(Incluso que yo mismo)
¿Quién quiere que yo quiera lo que creo que quiero?
(Wow)

Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra.

def get_sentences(texto):
    # Divide el texto en líneas
    lineas = texto.split('\n')
    # Filtra las líneas que contienen al menos una palabra
    oraciones_limpias = [linea.strip() for linea in lineas if len(linea.strip().split()) >= 1]
    return oraciones_limpias


oraciones_limpias = get_sentences(texto)
oraciones_limpias

len(oraciones_limpias) == 87

split = int(len(oraciones_limpias) * 0.8)
train_corpus = oraciones_limpias[:split]
test_corpus = oraciones_limpias[split:]

len(train_corpus), len(test_corpus)

### 6.b Estimación de N-gramas (0.5 puntos)

Defina una función que reciba una lista de oraciones de un corpus y un N que indique el tamaño de los N-gramas. La función debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe añadir un token especial al inicio o final de cada oración según corresponda (ver clases del curso).

from nltk.tokenize import word_tokenize

import nltk
nltk.download('punkt')

from collections import Counter

def n_grams(corpus, n=3):
    # Inicializa un contador para almacenar la frecuencia de los n-gramas
    n_grams_freq = Counter()
    # Recorre cada oración en el corpus
    for sentence in corpus:
        # Tokeniza la oración
        tokens = word_tokenize(sentence)
        # Añade tokens especiales al inicio y al final de la lista de tokens
        tokens = ['<s>'] * (n-1) + tokens + ['</s>']
        # Genera los n-gramas y actualiza sus frecuencias
        n_grams_freq.update([tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)])
    return n_grams_freq

n_grams(train_corpus, n=1)


n_grams(train_corpus, n=2)

n_grams(train_corpus, n=3)


Debe mostrar que su método funciona para $N = 1,2,3$.

## P7. Perplexity (1 punto)

En esta sección evaluarán su modelo de n-gramas y determinarán la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:

$$
\text{Perplexity} = 2^{-l} \quad \quad l = \frac{1}{M} \sum_{i=1}^{m} \log p(s_i)
$$

con $m$ el número de oraciones del corpus y $M$ el tamaño del vocabulario.

### 7.a Obtener probabilidades (0.5 puntos)

En esta sección implementará una función que determine la probabilidad de una oración.

Defina una función que reciba una oración, un diccionario con n-gramas y el valor de $n$. La función debe entregar la probabilidad de cualquier oración.

**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario.

def get_probability(sentence, n_grams_frequency, n):
    tokens = ['<s>'] * (n-1) + sentence.split() + ['</s>']
    V = len(set([token for n_gram in n_grams_frequency.keys() for token in n_gram])) + 1  # +1 for OOV (Out of Vocabulary) token
    
    probability_log_sum = 0
    for i in range(n-1, len(tokens)):
        n_gram = tuple(tokens[i-n+1:i+1])
        prefix = tuple(tokens[i-n+1:i])
        
        # Calculate counts
        n_gram_count = n_grams_frequency.get(n_gram, 0)
        prefix_count = sum([count for key, count in n_grams_frequency.items() if key[:n-1] == prefix])
        
        # Apply Laplace smoothing
        probability = (n_gram_count + 1) / (prefix_count + V)
        probability_log_sum += math.log(probability)
    
    return math.exp(probability_log_sum)


Pruebe su función con oraciones frecuentes y comente sus resultados
# Calcula los n-gramas para N = 1, 2, 3 usando el corpus de entrenamiento
n_grams_1 = n_grams(train_corpus, n=1)
n_grams_2 = n_grams(train_corpus, n=2)
n_grams_3 = n_grams(train_corpus, n=3)

# Selecciona algunas oraciones del conjunto de prueba para evaluar
test_sentences = test_corpus[:5]  # Se toman las primeras 5

# Función para imprimir las probabilidades de un conjunto de oraciones para un determinado N
def print_sentence_probabilities(sentences, n_grams_frequency, n):
    print(f"\nProbabilidades para N = {n}:")
    for sentence in sentences:
        probability = get_probability(sentence, n_grams_frequency, n)
        print(f"Oración: '{sentence}'\nProbabilidad: {probability}\n")

# Imprime las probabilidades para N = 1, 2, 3
print_sentence_probabilities(test_sentences, n_grams_1, 1)
print_sentence_probabilities(test_sentences, n_grams_2, 2)
print_sentence_probabilities(test_sentences, n_grams_3, 3)


### 7.b Perplexity en conjunto de test (0.5 puntos)

En esta sub-sección deberá calcular la perplejidad del corpus de test.


Defina una función que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la función de la sección anterior.


def get_perplexity(corpus, n):
    n_grams_frequency = n_grams(corpus, n)
    
    # Aquí, `corpus` es el corpus de test.
    # Calcular la probabilidad logarítmica total de todas las oraciones en el corpus de test
    total_log_probability = 0
    M = 0  # Total number of tokens
    
    for sentence in corpus:
        # Calcular la probabilidad de la oración actual y sumar su logaritmo al total
        sentence_probability = get_probability(sentence, n_grams_frequency, n)
        total_log_probability += math.log(sentence_probability)
        
        # Actualizar el contador total de tokens
        M += len(sentence.split()) + n - 1  # +n-1 por los tokens de inicio/final añadidos
    
    # Calcular el promedio de la probabilidad logarítmica por token
    l = total_log_probability / M
    
    # Calcular y devolver la perplejidad
    perplexity = math.pow(2, -l)
    return perplexity

## P8. Interpolación Lineal (0.5 puntos)

Cree una función que obtenga la probabilidad de una oración interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\lambda_1, \lambda_2$ y $\lambda_3$ respectivamente. Para esto use las funciones que creó anteriormente.


def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):
  ## Implementar aquí
  pass
  ##

