{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrkZWMLZB8z"
      },
      "source": [
        "# Tarea 2: Naive Bayes, Linear Models y Neural Networks\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto√±o 2024)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97b4IJjZGxM"
      },
      "source": [
        "## Tarjeta de identificaci√≥n\n",
        "\n",
        "**Nombres:**\n",
        "\n",
        "```- Ignacio Albornoz```\n",
        "\n",
        "```- Eduardo Silva```\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** 30/04.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:** 4 horas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKcZMFlmZ3b9"
      },
      "source": [
        "## Instrucciones\n",
        "Bienvenid@s a la segunda tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te√≥ricos de las √∫ltimas semanas de clases posteriores a la tarea 1, enfocado principalmente en **Naive Bayes**, **Linear Models** y **Neural Networks**. Si a√∫n no has visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una una parte pr√°ctica con el f√≠n de introducirlos a la programaci√≥n en Python enfocada en NLP.\n",
        "\n",
        "* La tarea es en **grupo** (maximo hasta 3 personas).\n",
        "* La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "* El formato de entrega es este mismo Jupyter Notebook.\n",
        "* Al momento de la revisi√≥n su c√≥digo ser√° ejecutado. Por favor verifiquen que su entrega no tenga errores de compilaci√≥n.\n",
        "* Completar la tarjeta de identificaci√≥n. Sin ella no podr√° tener nota.\n",
        "\n",
        "> **Importante:** Esta tarea tiene varios resultados experimentales que pueden variar de acuerdo a sus propias implementaciones. No se busca que los resultados sean exactamente los mismos (por ejemplo, que el accuracy fue el mismo que el que esta en la tarea). Lo importante es que implementen sus funciones, las sepan explicar y que puedan hacer varios experimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnTrhOKraAw2"
      },
      "source": [
        "## Material de referencia\n",
        "\n",
        "Diapositivas del curso üìÑ\n",
        "    \n",
        "- [Naive Bayes](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-NB.pdf)\n",
        "- [Linear Models](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-linear.pdf)\n",
        "- [Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-neural.pdf)\n",
        "\n",
        "Videos del curso üì∫\n",
        "\n",
        "- Naive Bayes: [Parte 1](https://www.youtube.com/watch?v=kG9BK9Oy1hU), [Parte 2](https://www.youtube.com/watch?v=Iqte5kKHvzE), [Parte 3](https://www.youtube.com/watch?v=TSJg0_X3Abk)\n",
        "\n",
        "- Linear Models: [Parte 1](https://www.youtube.com/watch?v=zhBxDsNLZEA), [Parte 2](https://www.youtube.com/watch?v=Fooua_uaWSE), [Parte 3](https://www.youtube.com/watch?v=DqbzhdQa1eQ), [Parte 4](https://www.youtube.com/watch?v=1nfWWXqfAzA)\n",
        "\n",
        "- Neural Networks: [Parte 1](https://www.youtube.com/watch?v=oHZHA8h2xN0), [Parte 2](https://www.youtube.com/watch?v=2lXank0W6G4), [Parte 3](https://www.youtube.com/watch?v=BUDIi9qItzY), [Parte 4](https://www.youtube.com/watch?v=KKN2Ipy-vGk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmC5SqOZfv1m"
      },
      "source": [
        "## P0. Cargar un dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldJFqRlCYSa-"
      },
      "source": [
        "Importamos algunas librerias que seran utiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QytPBlbvhsU6",
        "outputId": "de531db1-29a2-40e4-c462-0b0d136d6cc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN-mzGtAYVu-"
      },
      "source": [
        "Inicializamos el dataset con particiones de entrenamiento y test. Es un dataset de clasificacion multi-clase de oraciones. Cada oracion puede tener una unica etiqueta ?, + o -. Donde ? indica que la oracion es una pregunta, - que la oracion es negativa y + positiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bcaT6DquoXOo"
      },
      "outputs": [],
      "source": [
        "document = namedtuple(\n",
        "    \"document\", (\"words\", \"class_\")  # avoid python's keyword collision\n",
        ")\n",
        "\n",
        "raw_train_set = [\n",
        "              ['Do you have plenty of time?', '?'],\n",
        "              ['Does she have enough money?','?'],\n",
        "              ['Did they have any useful advice?','?'],\n",
        "              ['What day is today?','?'],\n",
        "              [\"I don't have much time\",'-'],\n",
        "              [\"She doesn't have any money\",'-'],\n",
        "              [\"They didn't have any advice to offer\",'-'],\n",
        "              ['Have you plenty of time?','?'],\n",
        "              ['Has she enough money?','?'],\n",
        "              ['Had they any useful advice?','?'],\n",
        "              [\"I haven't much time\",'-'],\n",
        "              [\"She hasn't any money\",'-'],\n",
        "              [\"He hadn't any advice to offer\",'-'],\n",
        "              ['How are you?','?'],\n",
        "              ['How do you make questions in English?','?'],\n",
        "              ['How long have you lived here?','?'],\n",
        "              ['How often do you go to the cinema?','?'],\n",
        "              ['How much is this dress?','?'],\n",
        "              ['How old are you?','?'],\n",
        "              ['How many people came to the meeting?','?'],\n",
        "              ['I‚Äôm from France','+'],\n",
        "              ['I come from the UK','+'],\n",
        "              ['My phone number is 61709832145','+'],\n",
        "              ['I work as a tour guide for a local tour company','+'],\n",
        "              ['I‚Äôm not dating anyone','-'],\n",
        "              ['I live with my wife and children','+'],\n",
        "              ['I often do morning exercises at 6am','+'],\n",
        "              ['I run everyday','+'],\n",
        "              ['She walks very slowly','+'],\n",
        "              ['They eat a lot of meat daily','+'],\n",
        "              ['We were in France that day', '+'],\n",
        "              ['He speaks very fast', '+'],\n",
        "              ['They told us they came back early', '+'],\n",
        "              [\"I told her I'll be there\", '+']\n",
        "]\n",
        "tokenized_train_set = [document(words=tuple(word_tokenize(d[0].lower())), class_=d[1]) for d in raw_train_set]\n",
        "train_set = pd.DataFrame(data=tokenized_train_set)\n",
        "\n",
        "raw_test_set = [\n",
        "             ['Do you know who lives here?','?'],\n",
        "             ['What time is it?','?'],\n",
        "             ['Can you tell me where she comes from?','?'],\n",
        "             ['How are you?','?'],\n",
        "             ['I fill good today', '+'],\n",
        "             ['There is a lot of history here','+'],\n",
        "             ['I love programming','+'],\n",
        "             ['He told us not to make so much noise','+'],\n",
        "             ['We were asked not to park in front of the house','+'],\n",
        "             [\"I don't have much time\",'-'],\n",
        "             [\"She doesn't have any money\",'-'],\n",
        "             [\"They didn't have any advice to offer\",'-'],\n",
        "             ['I am not really sure','+']\n",
        "]\n",
        "tokenized_test_set = [document(words=tuple(word_tokenize(d[0].lower())), class_=d[1]) for d in raw_test_set]\n",
        "test_set = pd.DataFrame(data=tokenized_test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cIkiUTOY8Ep"
      },
      "source": [
        "Separar en X e y, donde X son oraciones tokenizadas e y es la clase a predecir (o target)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ALoL0Xk9pJhU",
        "outputId": "ff24cc06-2de9-46c0-daf1-297670d257a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>class_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(i, do, n't, have, much, time)</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>(i, work, as, a, tour, guide, for, a, local, t...</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(i, often, do, morning, exercises, at, 6am)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(they, did, n't, have, any, advice, to, offer)</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(how, are, you, ?)</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(he, had, n't, any, advice, to, offer)</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>(they, told, us, they, came, back, early)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(how, long, have, you, lived, here, ?)</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(my, phone, number, is, 61709832145)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(how, much, is, this, dress, ?)</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                words class_\n",
              "4                      (i, do, n't, have, much, time)      -\n",
              "23  (i, work, as, a, tour, guide, for, a, local, t...      +\n",
              "26        (i, often, do, morning, exercises, at, 6am)      +\n",
              "6      (they, did, n't, have, any, advice, to, offer)      -\n",
              "13                                 (how, are, you, ?)      ?\n",
              "12             (he, had, n't, any, advice, to, offer)      -\n",
              "32          (they, told, us, they, came, back, early)      +\n",
              "15             (how, long, have, you, lived, here, ?)      ?\n",
              "22               (my, phone, number, is, 61709832145)      +\n",
              "17                    (how, much, is, this, dress, ?)      ?"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train = train_set.drop(columns=\"class_\"), train_set[\"class_\"]\n",
        "pd.concat([X_train, y_train], axis=1).sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSHQ_s9rZE6k"
      },
      "source": [
        "Cantidad de oraciones por clase:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "djD7TovViVuB",
        "outputId": "c61bbe00-ebf3-4ed6-a71c-dccfceebd2e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class_</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>+</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>?</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        words\n",
              "class_       \n",
              "+          13\n",
              "-           7\n",
              "?          14"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.groupby(\"class_\").count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQNS_HatZKBg"
      },
      "source": [
        "(X, y) para el conjunto de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5i0O-7-IpLbX",
        "outputId": "84b2ba44-575d-4700-81c6-1b65145e4fe0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>class_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(he, told, us, not, to, make, so, much, noise)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(i, am, not, really, sure)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(what, time, is, it, ?)</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(i, fill, good, today)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(i, do, n't, have, much, time)</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(can, you, tell, me, where, she, comes, from, ?)</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(they, did, n't, have, any, advice, to, offer)</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(there, is, a, lot, of, history, here)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(do, you, know, who, lives, here, ?)</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(i, love, programming)</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               words class_\n",
              "7     (he, told, us, not, to, make, so, much, noise)      +\n",
              "12                        (i, am, not, really, sure)      +\n",
              "1                            (what, time, is, it, ?)      ?\n",
              "4                             (i, fill, good, today)      +\n",
              "9                     (i, do, n't, have, much, time)      -\n",
              "2   (can, you, tell, me, where, she, comes, from, ?)      ?\n",
              "11    (they, did, n't, have, any, advice, to, offer)      -\n",
              "5             (there, is, a, lot, of, history, here)      +\n",
              "0               (do, you, know, who, lives, here, ?)      ?\n",
              "6                             (i, love, programming)      +"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test, y_test = test_set.drop(columns=\"class_\"), test_set[\"class_\"]\n",
        "pd.concat([X_test, y_test], axis=1).sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdwzchFGZNmf"
      },
      "source": [
        "Cantidad de oraciones por clase en el conjunto de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "5FXC-oNNpQGw",
        "outputId": "9648b16b-fadc-4c09-da70-2d191b678a9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class_</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>+</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>?</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        words\n",
              "class_       \n",
              "+           6\n",
              "-           3\n",
              "?           4"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set.groupby(\"class_\").count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTfP4UGXZUSX"
      },
      "source": [
        "**Importante:** Hasta el momento hemos creado nuestros conjuntos de train y test. A continuacion ustedes deben implementar tres modelos de clasificacion: Naive-bayes, Linear Model y Neural Network. Aqui va un resumen de cada pregunta y lo que se les pide implementar:\n",
        "\n",
        "* P1: Naive-bayes\n",
        " - Implementar `fit` y `predict`\n",
        " - Entrenar\n",
        " - Evaluar\n",
        "\n",
        "* P2: Linear Model\n",
        " - Implementar `fit` con *on-line gradient descent* y `predict`\n",
        " - Entrenar\n",
        " - Evaluar\n",
        "\n",
        "* P3: Neural Network\n",
        " - Implementar un iterador de datos con `datasets` y `dataloaders`\n",
        " - Implementar una red neuronal con `pytorch`\n",
        " - Implementar loop de entrenamiento de una NN\n",
        " - Entrenar\n",
        " - Evaluar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxYRIr-Ob010"
      },
      "source": [
        "## P1. Implementar y evaluar Multinomial Naive-Bayes (2 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWZGccxjcFE-"
      },
      "source": [
        "### Clase para clasificador\n",
        "\n",
        "Cree una clase MyMultinomialNB que en su inicializador reciba el par√°metro alpha para su clasficador.\n",
        "\n",
        "Adem√°s, debe implementar los m√©todos `fit(X, y)`y `predict(X)`.\n",
        "\n",
        "```python\n",
        "class MyMultinomialNB():\n",
        "  def __init__(self, alpha, ...):\n",
        "    ...\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    ...\n",
        "  \n",
        "  def predict(self, X):\n",
        "    ...\n",
        "    return prediction\n",
        "```\n",
        "Para computar el entrenamiento de nuestro clasificador debemos:\n",
        "- extraer el vocabulario,\n",
        "- determinar las probabilidades $p(c_j)$ para cada una de las clases posibles,\n",
        "- determinar las probabilidades $p(w_i|c_j)$ para cada una de las palabras y cada una de las clases.\n",
        "\n",
        "Para lograr lo anterior, tambi√©n deber√°n implementar el m√©todo `predict_proba(X)`:\n",
        "\n",
        "```python\n",
        "  def predict_proba(self, X):\n",
        "    return prob\n",
        "```\n",
        "\n",
        "**Underflow prevention:** En vez de hacer muchas multiplicaciones de `float`s, reempl√°cenlas por sumas de logaritmos para prevenir errores de precisi√≥n. (Revisen la diapo 26 de las slides).\n",
        "\n",
        "En su implementaci√≥n deben considerar la tecnica de *Laplace Smoothing* vista en clases. Especificamente considere que su clase `MyMultinomialNB` reciba un par√°metro `alpha` no negativo (es decir, mayor o igual a cero). De tal forma que el la probabilidad de una palabra $w$ dado la clase $c$ viene dado por lo siguiente:\n",
        "\n",
        "$$\n",
        "p_\\alpha (w|c) = \\frac{\\#(w, c) + \\alpha}{N + \\alpha |V|}\n",
        "$$\n",
        "\n",
        "donde $\\alpha$ es el par√°metro `alpha` de *Laplace Smoothing*. Mientras que los otras notaciones corresponden a\n",
        "\n",
        "* $\\#(w, c)$ numero de veces que ocurre la palabra $w$ en documentos con la clase $c$ (pensar en un gran documento $D_c$ que concatena todos los documentos de clase $c$ y luego calcula la frecuencia de la palabra $w$ en $D_c$),\n",
        "* $N$ es igual a $\\sum \\{\\#(w', c): w' \\in V\\}$ donde $V$ es el vocabulario,\n",
        "* $|V|$ tama√±o del vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0hFPME1aU9o"
      },
      "source": [
        "### Implementaci√≥n (1.5 pts.)\n",
        "\n",
        "Escriba aqu√≠ la implementaci√≥n de la clase `MyMultinomialNB`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JU5i9li8g7CS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MyMultinomialNB():\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.class_log_prior_ = {}\n",
        "        self.word_log_prob_ = {}\n",
        "        self.vocab = set()\n",
        "        self.word_counts = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        class_counts = y.value_counts()\n",
        "        word_counts = {c: {} for c in class_counts.keys()}\n",
        "        for text, label in zip(X.words, y):  # Ensure to access the 'words' column from X\n",
        "            for word in text:\n",
        "                if word not in word_counts[label]:\n",
        "                    word_counts[label][word] = 0\n",
        "                word_counts[label][word] += 1\n",
        "                self.vocab.add(word)\n",
        "        \n",
        "        total_docs = y.shape[0]\n",
        "        for c in class_counts.keys():\n",
        "            self.class_log_prior_[c] = np.log(class_counts[c] / total_docs)\n",
        "            total_count = sum(word_counts[c].values())\n",
        "            denom = total_count + self.alpha * len(self.vocab)\n",
        "            self.word_log_prob_[c] = {}\n",
        "            for word in self.vocab:\n",
        "                count = word_counts[c].get(word, 0)  # Use get to safely access count\n",
        "\n",
        "                if (count + self.alpha) == 0:\n",
        "                    self.word_log_prob_[c][word] = -np.inf  # Log of zero probability\n",
        "                else:\n",
        "                    self.word_log_prob_[c][word] = np.log((count + self.alpha) / denom)\n",
        "\n",
        "        \n",
        "        self.word_counts = word_counts\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        proba = []\n",
        "        for text in X.words:  # Ensure to access the 'words' column from X\n",
        "            class_probs = {c: self.class_log_prior_[c] for c in self.class_log_prior_}\n",
        "            for c in self.word_log_prob_:\n",
        "                for word in text:\n",
        "                    if word in self.word_log_prob_[c]:\n",
        "                        class_probs[c] += self.word_log_prob_[c][word]\n",
        "                    else:\n",
        "                        total_count = sum(self.word_counts[c].values())\n",
        "\n",
        "                        if self.alpha == 0:\n",
        "                            class_probs[c] += -np.inf\n",
        "                        else:\n",
        "                            class_probs[c] += np.log(self.alpha / (total_count + self.alpha * len(self.vocab)))\n",
        "\n",
        "\n",
        "            proba.append(class_probs)\n",
        "        return proba\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        predictions = [max(p, key=p.get) for p in proba]\n",
        "        return pd.Series(predictions, index=X.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY0j4Ruy0Cxr"
      },
      "source": [
        "### Entrenamiento (0.2 pts.)\n",
        "A continuaci√≥n, inicialicen y entrenen (ajusten) su clasificador con los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EuLl606ZjN4U"
      },
      "outputs": [],
      "source": [
        "nb_model = MyMultinomialNB(alpha=0.1)\n",
        "nb_model.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvTzP9vPjfFH"
      },
      "source": [
        "Pru√©benlo utilizando el m√©todo `predict()` que implementaron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "j5wph2IQuAzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQtmK4jfi8mP",
        "outputId": "296e2ea1-eb10-44ae-b91a-6bbcd503cc63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     ?\n",
            "1     ?\n",
            "2     ?\n",
            "3     ?\n",
            "4     -\n",
            "5     -\n",
            "6     -\n",
            "7     ?\n",
            "8     ?\n",
            "9     ?\n",
            "10    -\n",
            "11    -\n",
            "12    -\n",
            "13    ?\n",
            "14    ?\n",
            "15    ?\n",
            "16    ?\n",
            "17    ?\n",
            "18    ?\n",
            "19    ?\n",
            "20    +\n",
            "21    +\n",
            "22    +\n",
            "23    +\n",
            "24    -\n",
            "25    +\n",
            "26    +\n",
            "27    +\n",
            "28    +\n",
            "29    +\n",
            "30    +\n",
            "31    +\n",
            "32    +\n",
            "33    +\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Predict train-set\n",
        "y_pred = nb_model.predict(X_train)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "702uKpJLtPJj",
        "outputId": "2a8c549a-939d-410e-f286-b9263b63d30b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       1.00      1.00      1.00        13\n",
            "           -       1.00      1.00      1.00         7\n",
            "           ?       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        34\n",
            "   macro avg       1.00      1.00      1.00        34\n",
            "weighted avg       1.00      1.00      1.00        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Metricas en el conjunto de train\n",
        "print(classification_report(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzRqkuso1PWT"
      },
      "source": [
        "### Evaluaci√≥n (0.3 pts.)\n",
        "\n",
        "Ahora probar√°n el funcionamiento de su clasificador con un conjunto de test.  Habiendo entrenado su clasificador, clasifiquen los documentos del conjunto de prueba `test_set` usando el m√©todo `predict`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjMuND9djskK",
        "outputId": "bda9e6b9-d66a-4b18-8620-ccf1fba523b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       1.00      0.50      0.67         6\n",
            "           -       0.50      1.00      0.67         3\n",
            "           ?       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.77        13\n",
            "   macro avg       0.83      0.83      0.78        13\n",
            "weighted avg       0.88      0.77      0.77        13\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjvzyLHJVFdg"
      },
      "source": [
        "Comenten sus resultados. Estudien que ocurre para alpha=0, 1 y L donde L es un numero muy grande.\n",
        "\n",
        "```\n",
        "\n",
        "Para el modelo MyMultinomialNB con un Œ±=0.1, los resultados mostraron una precisi√≥n perfecta en el conjunto de entrenamiento con valores de precisi√≥n, sensibilidad y medida F1 de 1.00 para todas las clases. Esto indica que el modelo pudo clasificar correctamente todas las instancias de entrenamiento. Sin embargo, cuando el modelo se aplic√≥ al conjunto de prueba, la precisi√≥n general disminuy√≥ a 0.77, con variaciones significativas en las m√©tricas por clase. La clase '+' tuvo una precisi√≥n de 1.00 pero una sensibilidad de solo 0.50, lo que indica que el modelo no detect√≥ todas las instancias positivas correctamente. En contraste, la clase '-' mostr√≥ una precisi√≥n m√°s baja de 0.50, pero una sensibilidad de 1.00, indicando que mientras todas las instancias negativas se detectaron, tambi√©n hubo falsos positivos.\n",
        "\n",
        "Cuando se analiza el impacto del valor de Œ± en el rendimiento del clasificador, la configuraci√≥n de Œ±=0 podr√≠a llevar a problemas con palabras no vistas durante el entrenamiento, ya que la probabilidad asignada a estas ser√≠a cero, lo cual podr√≠a afectar negativamente la capacidad del modelo para realizar predicciones correctas sobre nuevos datos.\n",
        "\n",
        "Al aumentar Œ± a 1, se implementa el suavizado de Laplace est√°ndar. Esto puede ayudar a manejar mejor las palabras no vistas al evitar probabilidades cero, ofreciendo un balance m√°s estable entre la detecci√≥n de nuevas palabras y la clasificaci√≥n basada en el entrenamiento previo.\n",
        "\n",
        "Un Œ± muy alto, como 1000, asignar√≠a una importancia excesiva al suavizado, probablemente resultando en que todas las palabras tengan probabilidades similares condicionadas a la clase, independientemente de su frecuencia real en los datos. Esto podr√≠a diluir caracter√≠sticas l√©xicas distintivas de cada clase y reducir la capacidad del modelo para diferenciar entre clases basado en el texto, posiblemente empeorando significativamente el rendimiento en datos no vistos.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "```\n",
        "Se proceden a calcular las m√©tricas para los 3 casos de Œ± con el fin de verificar si se cumplen estas hip√≥tesis.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00         6\n",
            "           -       1.00      1.00      1.00         3\n",
            "           ?       0.40      1.00      0.57         4\n",
            "\n",
            "    accuracy                           0.54        13\n",
            "   macro avg       0.47      0.67      0.52        13\n",
            "weighted avg       0.35      0.54      0.41        13\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_model = MyMultinomialNB(alpha=0)\n",
        "nb_model.fit(X_train, y_train);\n",
        "\n",
        "y_pred = nb_model.predict(X_test)\n",
        "# Specify zero_division=0 to handle divisions by zero in precision calculation\n",
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       1.00      0.50      0.67         6\n",
            "           -       0.50      1.00      0.67         3\n",
            "           ?       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.77        13\n",
            "   macro avg       0.83      0.83      0.78        13\n",
            "weighted avg       0.88      0.77      0.77        13\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_model = MyMultinomialNB(alpha=1)\n",
        "nb_model.fit(X_train, y_train);\n",
        "\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00         6\n",
            "           -       0.00      0.00      0.00         3\n",
            "           ?       0.31      1.00      0.47         4\n",
            "\n",
            "    accuracy                           0.31        13\n",
            "   macro avg       0.10      0.33      0.16        13\n",
            "weighted avg       0.09      0.31      0.14        13\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_model = MyMultinomialNB(alpha=1000)\n",
        "nb_model.fit(X_train, y_train);\n",
        "\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "El an√°lisis emp√≠rico de los resultados con diferentes valores de Œ± para el clasificador MyMultinomialNB muestra variaciones significativas en el rendimiento en el conjunto de prueba, reflejando la importancia cr√≠tica de este par√°metro en la generalizaci√≥n del modelo.\n",
        "\n",
        "Con Œ± = 0, que no incluye ning√∫n suavizado, se observa un deterioro marcado en la clasificaci√≥n de las clases '+'. Aqu√≠, la precisi√≥n y sensibilidad son ambas 0.00, indicando que el modelo no logr√≥ identificar correctamente ninguna instancia de esta clase. Esto es t√≠pico de un modelo sin suavizado, ya que las palabras no vistas durante el entrenamiento resultan en probabilidades condicionadas de cero, incapacitando al modelo para predecir clases con estas palabras nuevas. No obstante, para la clase '-', el modelo alcanz√≥ una precisi√≥n y sensibilidad perfectas de 1.00, mostrando que pudo identificar y clasificar correctamente todas las instancias negativas sin errores. La clase '?' tuvo un desempe√±o aceptable con una sensibilidad de 1.00 y una precisi√≥n de 0.40, sugiriendo que, aunque identific√≥ todas las instancias de esta clase, tambi√©n asign√≥ err√≥neamente otras clases a '?'. Esto resulta en una precisi√≥n m√°s baja y una medida F1 de 0.57.\n",
        "\n",
        "Cuando Œ± = 1, el modelo emplea suavizado est√°ndar de Laplace, lo que mejora notablemente el equilibrio en el rendimiento a trav√©s de las clases. La precisi√≥n y sensibilidad para la clase '+' mejoraron a 1.00 y 0.50, respectivamente, indicando que el modelo ahora puede identificar correctamente algunas de las instancias positivas. La clase '-' tambi√©n muestra mejoras con una precisi√≥n de 0.50 y una sensibilidad de 1.00, reflejando la capacidad del modelo para reconocer todas las instancias negativas, aunque con cierta propensi√≥n a clasificar incorrectamente otras clases como '-'. La clase '?' mantiene un rendimiento perfecto en precisi√≥n y sensibilidad.\n",
        "\n",
        "Finalmente, con Œ± = 1000, un valor extremadamente alto que favorece un suavizado excesivo, el rendimiento general del modelo se desploma. Las clases '+' y '-' muestran tanto precisi√≥n como sensibilidad de 0.00, lo que significa que el modelo es completamente incapaz de identificar estas instancias correctamente. Esto se debe a que un Œ± muy alto hace que las frecuencias observadas tengan poco impacto en las probabilidades calculadas, resultando en que el modelo no pueda distinguir adecuadamente entre las clases basadas en caracter√≠sticas l√©xicas. La clase '?' sigue detect√°ndose correctamente (sensibilidad de 1.00), pero la precisi√≥n es solo de 0.31, lo que refleja clasificaciones incorrectas asignadas a esta categor√≠a.\n",
        "\n",
        "Estos resultados emp√≠ricos resaltan c√≥mo diferentes configuraciones de Œ± impactan significativamente la capacidad del modelo para generalizar sobre datos no vistos, ilustrando la importancia de seleccionar un valor de suavizado que ofrezca un equilibrio entre manejar adecuadamente nuevas palabras y mantener la precisi√≥n l√©xica entre clases.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNSdg__vb6J7"
      },
      "source": [
        "## P2. Implementar y evaluar Linear Models (2 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSlhzDQ5ac3u"
      },
      "source": [
        "### Clase para clasificador\n",
        "\n",
        "Cree una clase MyLinearModel para su clasficador. Debe implementar los m√©todos `fit(X, y, learning_rate, epochs)`y `predict(X)`.\n",
        "\n",
        "```python\n",
        "class MyLinearModel():\n",
        "  def __init__(self, ...):\n",
        "    ...\n",
        "\n",
        "  def fit(self, X, y, learning_rate, epochs):\n",
        "    ...\n",
        "  \n",
        "  def predict(self, X):\n",
        "    ...\n",
        "    return prediction\n",
        "```\n",
        "\n",
        "El modelo lineal que debe implementar viene dado por:\n",
        "$$\n",
        "\\vec{\\hat{y}} = \\text{softmax}(\\vec{x} \\cdot W + \\vec{b})\\\\\n",
        "\\vec{\\hat{y}}_{[i]} = \\frac{\\exp{z_i}}{\\sum_{j} \\exp{z_j}}\\\\\n",
        "z_i = \\vec{x} \\cdot W_{[:, i]} + \\vec{b}_{[i]}\n",
        "$$\n",
        "donde $\\vec{x}$ es un documento representado con bolsas de palabras (BoW), $W$ es la matriz de pesos y $\\vec{b}$ el bias.\n",
        "\n",
        "El modelo linea debe ajustarlo considerando como objetivo minimizar la cross-entropy loss, es decir:\n",
        "\n",
        "$$\n",
        "L_\\text{cross-entropy}(\\vec{\\hat{y}}, \\vec{y}) = - \\sum_i \\vec{y}_{[i]} \\log{ \\left( \\vec{\\hat{y}}_{[i]} \\right) }\n",
        "$$\n",
        "\n",
        "Para representar un documento `(i, am, not, really, sure)` vectorialmente, utilice `CountVectorizer` de sklearn. De esta manera, el documento queda representado como sigue:\n",
        "\n",
        "|    |   i |   he |   am |   are |   not |   yes |   really |   sure |\n",
        "|---:|----:|-----:|-----:|------:|------:|------:|---------:|-------:|\n",
        "|  0 |   1 |    0 |    1 |     0 |     1 |     0 |        1 |      1 |\n",
        "\n",
        "**Observaci√≥n:** Si el documento repite palabras entonces tendr√° un n√∫mero mayor a 1. Si el documento no tiene la palabra entonces tiene un 0. Pensar que las palabras `(he, are, yes)` provienen de otros documentos. Recuerde que el `CountVectorizer` se entrena con m√°s de un documento (es decir, un corpus). Aqu√≠ debe usar el conjunto de train.\n",
        "\n",
        "El m√©todo `fit(X, y, learning_rate, epochs)` debe ajustar un `CountVectorizer` para representar vectorialmente el documento. Debe guardar el `CountVectorizer` para cuando quiera hacer predicciones. Dentro del m√©todo `fit(X, y, learning_rate, epochs)` debe implementar *On-line gradient descent* (visto en clases), es decir, descenso de gradiente usando un data-point por iteraci√≥n. Su m√©todo debe ser capaz de recibir un `learning_rate` para ponderar el gradiente en cada iteraci√≥n y fijar un n√∫mero de `epochs`. Luego de entrenar debe guardar los pesos de su modelo lineal, es decir, $(W, \\vec{b})$.\n",
        "\n",
        "En el algoritmo de descenso de gradiente usando un data-point por iteraci√≥n, o *On-line gradient descent*, debe implementar manualmente las derivadas. Como conoce el modelo lineal y la funcion objetivo, entonces puede calcular manualmente las derivadas. Para ejemplificar, en cada paso del algoritmo de optimizacion debe actualizar los pesos $(W, \\vec{b})$ del siguiente modo:\n",
        "\n",
        "$$\n",
        "W \\leftarrow W - \\lambda \\nabla_{W} L_\\text{cross-entropy}\\\\\n",
        "\\vec{b} \\leftarrow \\vec{b} - \\lambda \\nabla_{\\vec{b}} L_\\text{cross-entropy}\\\\\n",
        "$$\n",
        "donde $\\lambda$ es el par√°metro `learning_rate`, $\\nabla_{W} L_\\text{cross-entropy}$ el gradiente de la Loss con repecto a la matriz de pesos $W$ y $\\nabla_{\\vec{b}} L_\\text{cross-entropy}$ para el bias $\\vec{b}$.\n",
        "\n",
        "Para implementar el algoritmo *On-line gradient descent* les recomendamos (no es obligatorio hacerlo de este modo) definir una funci√≥n `get_derivative_W(x, y_target, y_pred, n_classes)` que calcule $\\nabla_{W} L_\\text{cross-entropy}$ y lo mismo con una funci√≥n `get_derivative_b(y_target, y_pred, n_classes)` que calcule $\\nabla_{\\vec{b}} L_\\text{cross-entropy}$.\n",
        "\n",
        "Para implementar el m√©todo `predict(self, X)` debera usar su `CountVectorizer` definido en `fit(X, y, learning_rate, epochs)` para representar del mismo modo cualquier documento tanto en train como en test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqJhGTQS0rpv"
      },
      "source": [
        "### Implementaci√≥n (1.5 pts.)\n",
        "Implemente un modelo lineal con m√©todos `fit(X, y)` y `predict(X)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lO5zE2ArjifE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "## A√±adir aqu√≠ funciones auxiliares\n",
        "def softmax(x):\n",
        "    pass\n",
        "\n",
        "def get_derivative_W(x, y_target, y_pred, n_classes):\n",
        "  ## Implementar derivada\n",
        "  pass\n",
        "\n",
        "def get_derivative_b(y_target, y_pred, n_classes):\n",
        "  # Implementar derivadas\n",
        "  pass\n",
        "\n",
        "def get_preds_tests(X, y, linear_layer):\n",
        "  # Implementar m√©todo para obtener predicciones y ground-truth\n",
        "  pass\n",
        "\n",
        "## Implementar aqu√≠ su clase\n",
        "class MyLinearModel():\n",
        "\n",
        "  \"\"\"\n",
        "  y_pred = softmax(x @ W + b)\n",
        "  Loss = cross-entropy(y, y_pred)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"Inicializa el modelo\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, y, learning_rate, epochs, verbose=False):\n",
        "    \"\"\"Entrena el modelo a partir de datos de entrenamiento\n",
        "\n",
        "    Args:\n",
        "      X: Serie de pandas con documentos\n",
        "      y: Serie de pandas con clases (\"class_\") de los documentos\n",
        "      learning_rate: parametro learning rate del modelo\n",
        "      verbose: para imprimir mensajes de progreso\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "    \"\"\"\n",
        "\n",
        "    #### Empezar Online-gradient descent\n",
        "\n",
        "    pass\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"Predice las clases m√°s probables de una serie de documentos\n",
        "\n",
        "    Args:\n",
        "      X: Serie de pandas con documentos\n",
        "\n",
        "    Returns:\n",
        "      Serie de pandas con las clase de cada documento de X\n",
        "    \"\"\"\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANT3rY1QkhyZ"
      },
      "source": [
        "### Entrenamiento (0.2 pts.)\n",
        "Inicialicen y entrenen su clasificador con los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXY8ACuVIRb9",
        "outputId": "e5776a5f-27e9-4d78-cd16-ec3d35fa99db"
      },
      "outputs": [],
      "source": [
        "linear_model = MyLinearModel()\n",
        "linear_model.fit(\n",
        "    X_train, y_train,\n",
        "    learning_rate=0.02,\n",
        "    epochs=15,\n",
        "    verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDUL-ubzh04B"
      },
      "source": [
        "Pru√©benlo utilizando el m√©todo `predict()` que implementaron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JKjK3pUwL1w",
        "outputId": "d1fceb7a-70af-4029-a4c7-1a85f2d4c686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Predict train-set\n",
        "y_pred = linear_model.predict(X_train)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i6Qiu0RwP-w",
        "outputId": "1d9476ef-8d91-4531-c7f6-2ee2b425044c"
      },
      "outputs": [
        {
          "ename": "InvalidParameterError",
          "evalue": "The 'y_pred' parameter of classification_report must be an array-like or a sparse matrix. Got None instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Metricas en el conjunto de train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp_t2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 203\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp_t2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
            "\u001b[0;31mInvalidParameterError\u001b[0m: The 'y_pred' parameter of classification_report must be an array-like or a sparse matrix. Got None instead."
          ]
        }
      ],
      "source": [
        "# Metricas en el conjunto de train\n",
        "print(classification_report(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGzafGqr1GBX"
      },
      "source": [
        "### Evaluaci√≥n (0.3 pts.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Tj_g-Qh7hD"
      },
      "source": [
        "Ahora probar√°n el funcionamiento de su clasificador con un conjunto de test.  Habiendo entrenado su clasificador, clasifiquen los documentos del conjunto de prueba `test_set` usando el m√©todo `predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-03hyMeQ94e0",
        "outputId": "ada077ba-2ba1-49c3-87c0-3a7a66e99c13"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'linear_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'linear_model' is not defined"
          ]
        }
      ],
      "source": [
        "y_pred = linear_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gVYYq5h_CU"
      },
      "source": [
        "Comenten sus resultados. Estudien que ocurre para al menos tres combinaciones de learning rates y epochs, por ejemplo `learning_rate, epochs = (0.02, 15), (0.1, 10), (0.005, 30)`.\n",
        "\n",
        "```\n",
        "Comentar aqu√≠.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a71d7NNCfTna"
      },
      "source": [
        "## P3. Implementar y evaluar Neural Networks (2 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6eCZbdHkVvt"
      },
      "source": [
        "### Especificaciones del clasificador\n",
        "\n",
        "<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vSXJm5I61m6w0RHTwBL-iMyeFLr2wXBrKNYxdU8Bu1ymuCFPD9dAPsCzPfvIqwSr8uCiYvWMdnGy1if/pub?w=818&h=503\" >\n",
        "\n",
        "En esta √∫ltima pregunta, ustedes deber√°nimplementar y evaluar redes neuronales (como la de la figura de arriba). Para esto debera implementar tres secciones principales:\n",
        "\n",
        "1. Secci√≥n iterador,\n",
        "2. Secci√≥n modelo, y\n",
        "3. Secci√≥n loop de entrenamiento.\n",
        "\n",
        "> **Recomendaci√≥n:** Para completar esta pregunta puede guiarse del Auxiliar 2 (clase del d√≠a 18/04)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEtleHcI94Ae"
      },
      "source": [
        "*Seccion iterador*\n",
        "\n",
        "Para ayudarnos a con el entrenamiento y testing, vamos a utilizar las clases `Dataset` y `DataLoader` de `pytorch` ([ver documentaci√≥n](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)). En esta secci√≥n deber√° implementar un contenedor para su conjunto de datos usando la clase `Dataset` de `pytorch`. Para esto deber√° crear su propia clase `MyDataset` para gestionar los datos. √âsto le permitir√° iterar sobre el conjunto mediante el iterador `DataLoader` de `pytorch` y entrenar sin hacer ning√∫n pre-procesamiento extra a los datos.\n",
        "\n",
        "**Observaci√≥n:** Si considera por funcionalidad cambiar los par√°metros de la clase `MyDataset` puede hacerlo. Asimismo, puede definir otros par√°metros para los m√©todos de su clase.\n",
        "\n",
        "\n",
        "```python\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, bow_cols):\n",
        "      ...\n",
        "\n",
        "    def __len__(self):\n",
        "      ...\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      ...\n",
        "      return x_bow, label\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "758StzD796q6"
      },
      "source": [
        "*Secci√≥n modelo*\n",
        "\n",
        "En esta secci√≥n deber√°n implementar la clase `MyNeuralNetwork` del modulo de `pytorch` llamado `nn.Module` con el proposito de dise√±ar una red neuronal como la figura de arriba. Para mas detalle sobre las redes ver Clase NLP-Neural.pdf Slide n√∫mero 8.\n",
        "\n",
        "**Observaci√≥n:** La figura de arriba es solo ilustrativa, ustedes pueden variar la dimension input y output de la capa oculta. Sin embargo deben mantener fija la dimension de la entrada y salida de la red. La entrada depende del tama√±o del vocabulario. Mientras que la salida depende de la cantidad de clases de su problema de clasificaci√≥n (en nuestro caso igual a 3).\n",
        "\n",
        "Es importante que la clase `MyNeuralNetwork` tenga implementadas apropiadamente el `__init__` con las dimensiones y el `forward` con entrada tipo BoW retornando el √∫ltimo estado de la red (output layer). En el `forward` recomendamos utilizar funciones de activaci√≥n tipo `nn.ReLU`. Sin embargo, no es completamente obligatorio por lo que pueden usar otras.\n",
        "\n",
        "```python\n",
        "class MyNeuralNetwork(nn.Module):\n",
        "    def __init__(self,\n",
        "                 dim_vocab,\n",
        "                 num_classes,\n",
        "                 dim_hidden_input,\n",
        "                 dim_hidden_output):\n",
        "\n",
        "        super(MyNeuralNetwork, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "      ...\n",
        "\n",
        "    def forward(self, xs_bow):\n",
        "      ...\n",
        "      return last_state\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K2ocUUF99X5"
      },
      "source": [
        "*Secci√≥n loop de entrenamiento*\n",
        "\n",
        "En esta secci√≥n deber√°n implementar el loop de entrenamiento de su red neuronal. Para esto, primero deben definir un `criterion`, en nuestro caso `nn.CrossEntropyLoss()` con la libreria de `pytorch`. Sucesivamente debera definir un optimizador, en nuestro caso `optim.SGD` desde el modulo `optim` de `pytorch`.\n",
        "\n",
        "El loop de entrenamiento debe seguir la siguiente estructura:\n",
        "```python\n",
        "for epoch in range(epochs):\n",
        "  for (xs_bow, labels) in train_loader:\n",
        "    ...\n",
        "```\n",
        "\n",
        "donde `train_loader` proviene del iterador generado en la \"secci√≥n iterador\".\n",
        "\n",
        "Dentro de \"doble for\" debera conjugar apropiadamente `opti.zero_grad()`, `loss = criterion(...)`, `loss.backward()` y `opti.step()` con tal de entrenar correctamente su red neuronal. Incluso entrenar, ya que a veces si no se hace de forma correcta entonces tristemente ¬°su red no entrena!\n",
        "\n",
        "> **Recomendaci√≥n:** Puede guiarse del Auxiliar 2 para implementar el loop de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi1fdYw3kd-j"
      },
      "source": [
        "### Preparaci√≥n de la GPU y los datos de train/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-iWhEKOtgp0"
      },
      "source": [
        "Importar la libreria `pytorch` y `numpy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zWBi-34WAKnC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8mprHO5tbJv"
      },
      "source": [
        "Verificar que esta usando GPU. Sino, dir√≠gase a **Runtime > Change runtime type** y seleccione la opci√≥n **T4 GPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZU9DqaeAX-o",
        "outputId": "47d81b4c-ea07-4b53-f402-00551f5930a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3BvxVN-uefp"
      },
      "source": [
        "Preparaci√≥n de los conjuntos train y test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MfXfl3SZBSmF"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow = CountVectorizer(tokenizer=lambda x: list(x), preprocessor=lambda x: x, token_pattern=None)\n",
        "\n",
        "bow_train = pd.DataFrame(\n",
        "    bow.fit_transform(train_set[\"words\"]).toarray(),\n",
        "    columns=bow.get_feature_names_out()\n",
        ")\n",
        "bow_test = pd.DataFrame(\n",
        "    bow.transform(test_set[\"words\"]).toarray(),\n",
        "    columns=bow.get_feature_names_out()\n",
        ")\n",
        "\n",
        "bow_label_train = bow_train.astype(float).copy()\n",
        "bow_label_test = bow_test.astype(float).copy()\n",
        "\n",
        "map_from_class_to_int = {\n",
        "    \"?\": 0,\n",
        "    \"+\": 1,\n",
        "    \"-\": 2\n",
        "}\n",
        "\n",
        "bow_label_train[\"class_\"] = train_set[\"class_\"]\n",
        "bow_label_train[\"int_class_\"] = train_set[\"class_\"].apply(lambda x: map_from_class_to_int[x])\n",
        "\n",
        "bow_label_test[\"class_\"] = test_set[\"class_\"]\n",
        "bow_label_test[\"int_class_\"] = test_set[\"class_\"].apply(lambda x: map_from_class_to_int[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>'ll</th>\n",
              "      <th>61709832145</th>\n",
              "      <th>6am</th>\n",
              "      <th>?</th>\n",
              "      <th>a</th>\n",
              "      <th>advice</th>\n",
              "      <th>and</th>\n",
              "      <th>any</th>\n",
              "      <th>anyone</th>\n",
              "      <th>are</th>\n",
              "      <th>...</th>\n",
              "      <th>very</th>\n",
              "      <th>walks</th>\n",
              "      <th>we</th>\n",
              "      <th>were</th>\n",
              "      <th>what</th>\n",
              "      <th>wife</th>\n",
              "      <th>with</th>\n",
              "      <th>work</th>\n",
              "      <th>you</th>\n",
              "      <th>‚Äô</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34 rows √ó 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    'll  61709832145  6am  ?  a  advice  and  any  anyone  are  ...  very  \\\n",
              "0     0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "1     0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "2     0            0    0  1  0       1    0    1       0    0  ...     0   \n",
              "3     0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "4     0            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "5     0            0    0  0  0       0    0    1       0    0  ...     0   \n",
              "6     0            0    0  0  0       1    0    1       0    0  ...     0   \n",
              "7     0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "8     0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "9     0            0    0  1  0       1    0    1       0    0  ...     0   \n",
              "10    0            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "11    0            0    0  0  0       0    0    1       0    0  ...     0   \n",
              "12    0            0    0  0  0       1    0    1       0    0  ...     0   \n",
              "13    0            0    0  1  0       0    0    0       0    1  ...     0   \n",
              "14    0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "15    0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "16    0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "17    0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "18    0            0    0  1  0       0    0    0       0    1  ...     0   \n",
              "19    0            0    0  1  0       0    0    0       0    0  ...     0   \n",
              "20    0            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "21    0            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "22    0            1    0  0  0       0    0    0       0    0  ...     0   \n",
              "23    0            0    0  0  2       0    0    0       0    0  ...     0   \n",
              "24    0            0    0  0  0       0    0    0       1    0  ...     0   \n",
              "25    0            0    0  0  0       0    1    0       0    0  ...     0   \n",
              "26    0            0    1  0  0       0    0    0       0    0  ...     0   \n",
              "27    0            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "28    0            0    0  0  0       0    0    0       0    0  ...     1   \n",
              "29    0            0    0  0  1       0    0    0       0    0  ...     0   \n",
              "30    0            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "31    0            0    0  0  0       0    0    0       0    0  ...     1   \n",
              "32    0            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "33    1            0    0  0  0       0    0    0       0    0  ...     0   \n",
              "\n",
              "    walks  we  were  what  wife  with  work  you  ‚Äô  \n",
              "0       0   0     0     0     0     0     0    1  0  \n",
              "1       0   0     0     0     0     0     0    0  0  \n",
              "2       0   0     0     0     0     0     0    0  0  \n",
              "3       0   0     0     1     0     0     0    0  0  \n",
              "4       0   0     0     0     0     0     0    0  0  \n",
              "5       0   0     0     0     0     0     0    0  0  \n",
              "6       0   0     0     0     0     0     0    0  0  \n",
              "7       0   0     0     0     0     0     0    1  0  \n",
              "8       0   0     0     0     0     0     0    0  0  \n",
              "9       0   0     0     0     0     0     0    0  0  \n",
              "10      0   0     0     0     0     0     0    0  0  \n",
              "11      0   0     0     0     0     0     0    0  0  \n",
              "12      0   0     0     0     0     0     0    0  0  \n",
              "13      0   0     0     0     0     0     0    1  0  \n",
              "14      0   0     0     0     0     0     0    1  0  \n",
              "15      0   0     0     0     0     0     0    1  0  \n",
              "16      0   0     0     0     0     0     0    1  0  \n",
              "17      0   0     0     0     0     0     0    0  0  \n",
              "18      0   0     0     0     0     0     0    1  0  \n",
              "19      0   0     0     0     0     0     0    0  0  \n",
              "20      0   0     0     0     0     0     0    0  1  \n",
              "21      0   0     0     0     0     0     0    0  0  \n",
              "22      0   0     0     0     0     0     0    0  0  \n",
              "23      0   0     0     0     0     0     1    0  0  \n",
              "24      0   0     0     0     0     0     0    0  1  \n",
              "25      0   0     0     0     1     1     0    0  0  \n",
              "26      0   0     0     0     0     0     0    0  0  \n",
              "27      0   0     0     0     0     0     0    0  0  \n",
              "28      1   0     0     0     0     0     0    0  0  \n",
              "29      0   0     0     0     0     0     0    0  0  \n",
              "30      0   1     1     0     0     0     0    0  0  \n",
              "31      0   0     0     0     0     0     0    0  0  \n",
              "32      0   0     0     0     0     0     0    0  0  \n",
              "33      0   0     0     0     0     0     0    0  0  \n",
              "\n",
              "[34 rows x 100 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWdzeqbb1reG"
      },
      "source": [
        "### Implementaci√≥n (1.7 pts.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rvXmHBqlUfR"
      },
      "source": [
        "#### Iterador de conjunto de datos\n",
        "Implemente su clase `MyDataset` para acceder al dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7s8tFWCuBCin"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "  # Implementar aqu√≠ su iterador de datos\n",
        "\n",
        "    def __init__(self, data, bow_cols):\n",
        "        self.data = data\n",
        "        self.bow_cols = bow_cols\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = int(self.data.loc[index, \"int_class_\"])\n",
        "        x_bow = torch.tensor(self.data.loc[index, self.bow_cols]. # Obtenemos el vector x_{index}\n",
        "                             values.astype(float)).to(torch.float32) # y lo convertimos a tensor de float32\n",
        "        return x_bow, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK7lLpkXup49"
      },
      "source": [
        "Inicializar cada dataloader con sus cotenedor datos para train y test, y n√∫mero de batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    MyDataset(data = bow_label_train, bow_cols = bow_train.columns),\n",
        "    batch_size = 5, num_workers = 1, shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    MyDataset(data = bow_label_test, bow_cols = bow_test.columns),\n",
        "    batch_size = 5, num_workers = 1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DdOpdUnicoc"
      },
      "source": [
        "Ejemplo de prueba para un batch de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wGaYRzIaxr4",
        "outputId": "72b59685-b1c1-42fb-f2e2-052881edbd3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
              " tensor([0, 0, 0, 0, 2])]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "print( batch )\n",
        "print( batch[0].shape, sample[1].shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2qotKTXmDue"
      },
      "source": [
        "#### Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwBRaPKLhdoU"
      },
      "source": [
        "Implemente a continuaci√≥n su red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B_g0kYDXDFsW"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class MyNeuralNetwork(nn.Module):\n",
        "  # Implementar aqu√≠ su NN\n",
        "    def __init__(self,\n",
        "                 dim_vocab,\n",
        "                 num_classes,\n",
        "                 dim_hidden_input,\n",
        "                 dim_hidden_output):\n",
        "\n",
        "\n",
        "        super(MyNeuralNetwork, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "    \n",
        "\n",
        "        # Primera capa\n",
        "        self.first_layer = nn.Linear(dim_vocab, dim_hidden_input)\n",
        "\n",
        "        # Capa oculta\n",
        "        self.hidden_layer = nn.Linear(dim_hidden_input, dim_hidden_output)\n",
        "\n",
        "        # √öltima capa\n",
        "        self.last_layer = nn.Linear(dim_hidden_output, num_classes)\n",
        "\n",
        "        # Funci√≥n de activaci√≥n\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, xs_bow):\n",
        "      \"\"\"Calcula la ultima capa mediante las capas intermedias de la red\n",
        "\n",
        "      Args:\n",
        "        xs_bow: Tensor\n",
        "\n",
        "      Returns:\n",
        "        Tensor con los valores de prediccion\n",
        "      \"\"\"\n",
        "\n",
        "      ## Implementar aqu√≠ el forward-pass\n",
        "      # Hacemos el forward-pass\n",
        "      first_state = self.first_layer(xs_bow)\n",
        "      first_state = self.relu(first_state)\n",
        "\n",
        "      hidden_state = self.hidden_layer(first_state)\n",
        "      hidden_state = self.relu(hidden_state)\n",
        "\n",
        "      last_state = self.last_layer(hidden_state)\n",
        "\n",
        "      return last_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlUntk5IhX26"
      },
      "source": [
        "Ejemplo de prueba para su modelo NN para un batch de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid(s) 11560) exited unexpectedly",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
            "\u001b[1;31mEmpty\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m MyNeuralNetwork(\n\u001b[0;32m      2\u001b[0m     dim_vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mbow_cols),\n\u001b[0;32m      3\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      4\u001b[0m     dim_hidden_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      5\u001b[0m     dim_hidden_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m test(batch[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 11560) exited unexpectedly"
          ]
        }
      ],
      "source": [
        "test = MyNeuralNetwork(\n",
        "    dim_vocab=len(train_loader.dataset.bow_cols),\n",
        "    num_classes=3,\n",
        "    dim_hidden_input=10,\n",
        "    dim_hidden_output=5)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "\n",
        "test(batch[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Verifica si CUDA est√° disponible\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Imprime la versi√≥n de CUDA\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82_O2fAXEclt",
        "outputId": "39357b9e-c801-4b3e-c1f6-3dfbefcd6b03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1008, -0.0804, -0.3952],\n",
              "        [-0.1088, -0.0537, -0.4089],\n",
              "        [-0.1051, -0.0697, -0.4043],\n",
              "        [-0.0978, -0.0585, -0.4090],\n",
              "        [-0.0992, -0.0623, -0.4076]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = MyNeuralNetwork(\n",
        "    dim_vocab=len(train_loader.dataset.bow_cols),\n",
        "    num_classes=3,\n",
        "    dim_hidden_input=10,\n",
        "    dim_hidden_output=5).cuda()\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "\n",
        "test(batch[0].cuda())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urgN_j-HlKqm"
      },
      "source": [
        "#### Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NHDkwwlla-H"
      },
      "source": [
        "Consideren las siguientes funciones que les ser√°n utiles. Si lo desea puede modificarlas a su conveniencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj5Ws_0hlYT0"
      },
      "outputs": [],
      "source": [
        "def get_loss(net, iterator, criterion):\n",
        "    net.eval()\n",
        "    total_loss = 0\n",
        "    num_evals = 0\n",
        "    with torch.no_grad():\n",
        "      for xs_bow, labels in iterator:\n",
        "          xs_bow, labels = xs_bow.cuda(), labels.cuda()\n",
        "\n",
        "          logits = net(xs_bow)\n",
        "\n",
        "          loss = criterion(logits, labels)\n",
        "\n",
        "          total_loss += loss.item() * xs_bow.shape[0]\n",
        "          num_evals += xs_bow.shape[0]\n",
        "\n",
        "    return total_loss / num_evals\n",
        "\n",
        "def get_preds_tests_nn(net, iterator):\n",
        "  net.eval()\n",
        "  preds, tests = [], []\n",
        "  with torch.no_grad():\n",
        "    for xs_bow, labels in iterator:\n",
        "      xs_bow, labels = xs_bow.cuda(), labels.cuda()\n",
        "\n",
        "      logits = net(xs_bow)\n",
        "\n",
        "      soft_probs = nn.Sigmoid()(logits)\n",
        "\n",
        "      preds += np.argmax(soft_probs.tolist(), axis=1).tolist()\n",
        "      tests += labels.tolist()\n",
        "\n",
        "    return np.array(preds), np.array(tests)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ASceXqlblb"
      },
      "source": [
        "A continuaci√≥n, inicialicen y entrenen su clasificador con los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh2sqTWXGCmK",
        "outputId": "15c723f9-ce5e-4553-a07d-0cc3efff615e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoca 0 completada! Loss: 1.1054631629410911 Accuracy: 0.38235294117647056\n",
            "Epoca 1 completada! Loss: 1.0930101818898146 Accuracy: 0.38235294117647056\n",
            "Epoca 2 completada! Loss: 1.0800085768980139 Accuracy: 0.38235294117647056\n",
            "Epoca 3 completada! Loss: 1.056380967006964 Accuracy: 0.38235294117647056\n",
            "Epoca 4 completada! Loss: 0.9195144391235184 Accuracy: 0.47058823529411764\n",
            "Epoca 5 completada! Loss: 0.7975653784678263 Accuracy: 0.6176470588235294\n",
            "Epoca 6 completada! Loss: 0.6394507672418567 Accuracy: 0.7058823529411765\n",
            "Epoca 7 completada! Loss: 0.4972488123594838 Accuracy: 0.7647058823529411\n",
            "Epoca 8 completada! Loss: 0.5996851416523842 Accuracy: 0.6176470588235294\n",
            "Epoca 9 completada! Loss: 0.33634046876036067 Accuracy: 0.8235294117647058\n",
            "Epoca 10 completada! Loss: 0.2385189199601026 Accuracy: 0.8823529411764706\n",
            "Epoca 11 completada! Loss: 0.0932115251198411 Accuracy: 1.0\n",
            "Epoca 12 completada! Loss: 0.05484988332233008 Accuracy: 1.0\n",
            "Epoca 13 completada! Loss: 0.03735693112727912 Accuracy: 1.0\n",
            "Epoca 14 completada! Loss: 0.02796964330927414 Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "params = {\n",
        "    \"dim_vocab\": len(train_loader.dataset.bow_cols),\n",
        "    \"num_classes\": 3,\n",
        "    \"dim_hidden_input\": 5,\n",
        "    \"dim_hidden_output\": 5,\n",
        "    \"learning_rate\": 0.4,\n",
        "    \"epochs\": 15\n",
        "}\n",
        "\n",
        "# Inicialice su red neuronal\n",
        "net = MyNeuralNetwork(\n",
        "    dim_vocab=params[\"dim_vocab\"],\n",
        "    num_classes=params[\"num_classes\"],\n",
        "    dim_hidden_input=params[\"dim_hidden_input\"],\n",
        "    dim_hidden_output=params[\"dim_hidden_output\"]).cuda()\n",
        "\n",
        "# Definir la Loss = Cross-entropy\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# Definir el optimizador = SGD: Stochastic-gradient Descent\n",
        "opti = optim.SGD(net.parameters(), lr = params[\"learning_rate\"])\n",
        "\n",
        "# Definir el numero de epocas de entrenamiento\n",
        "epochs = params[\"epochs\"]\n",
        "\n",
        "## Implementar desde aqui el ciclo de entrenamiento\n",
        "## para cada epoca en el conjunto de train\n",
        "for epoch in range(epochs):\n",
        "  for (xs_bow, labels) in train_loader:\n",
        "\n",
        "    pass # Quitar esto cuando implementen el loop de entrenamiento\n",
        "\n",
        "  total_loss = get_loss(net, train_loader, criterion)\n",
        "  y_preds, y_tests = get_preds_tests_nn(net, train_loader)\n",
        "  acc = (y_preds == y_tests).sum() / y_preds.shape[0]\n",
        "\n",
        "  print(\"Epoca {} completada! Loss: {} Accuracy: {}\".format(epoch, total_loss, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAbQjdlrno1o"
      },
      "source": [
        "Pruebe su modelo entrenado con la funci√≥n `get_preds_tests_nn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1Ncs0lPbYKz",
        "outputId": "79536bb9-82a2-4efe-c628-efe64199fdc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        34\n",
            "   macro avg       1.00      1.00      1.00        34\n",
            "weighted avg       1.00      1.00      1.00        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ya no necesitara calcular gradientes para hacer inferencia\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Calcule el la predicci√≥n de su modelo y el ground-truth\n",
        "y_preds, y_tests = get_preds_tests_nn(net, train_loader)\n",
        "print(classification_report(y_tests, y_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-3tp4jR12TR"
      },
      "source": [
        "### Evaluaci√≥n (0.3 pts.)\n",
        "\n",
        "Ahora probar√°n el funcionamiento de su clasificador con un conjunto de test.  Habiendo entrenado su clasificador, clasifiquen los documentos del conjunto de prueba `test_set` usando la funci√≥n `get_preds_tests_nn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71KR1updZ4eL",
        "outputId": "81dc65e2-d3a2-4880-b222-715db6e36019"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89         4\n",
            "           1       1.00      0.83      0.91         6\n",
            "           2       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.92        13\n",
            "   macro avg       0.93      0.94      0.93        13\n",
            "weighted avg       0.94      0.92      0.92        13\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "y_preds, y_tests = get_preds_tests_nn(net, test_loader)\n",
        "print(classification_report(y_tests, y_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z2BxxUQoINV"
      },
      "source": [
        "Comenten sus resultados. Estudien que ocurre para al menos tres combinaciones de `(dim_hidden_input, dim_hidden_output)`.\n",
        "\n",
        "```\n",
        "Comentar aqu√≠.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
